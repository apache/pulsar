# PIP-322: Pulsar Rate Limiting Refactoring

# Motivation

The current rate limiting implementation in Apache Pulsar has several
known issues that impact performance and accuracy when operating Pulsar
clusters under load (detailed in [Problems to
Address](#problems-to-address)). This proposal outlines a refactor to
consolidate multiple existing options into a single improved solution.

The refactor aims to resolve numerous user complaints regarding default
Pulsar rate limiting being unusable. In addition, inconsistencies and
thread contention with existing rate limiters cause unpredictable
throttling and added latency.

Overhauling the built-in implementation will improve multi-tenancy,
allow Pulsar to scale to demanding workloads, and address longstanding
issues.

Rate limiters act as a conduit to more extensive capacity management and
Quality of Service (QoS) controls in Pulsar. They are integral to
Pulsar's core multi-tenancy features. This refactoring will pave the way
for future enhancements.

# Background Reading

To understand what we're trying to achieve, you should first read the
blog post "Proposal for Pulsar Rate Limiting Enhancements"
[here](https://codingthestreams.com/pulsar/2023/11/22/pulsar-slos-and-rate-limiting.html#proposal-for-pulsar-rate-limiting-enhancements).
Please also make sure to read the [Pulsar Community Meeting minutes
  2023/11/23](https://lists.apache.org/thread/y1sqpyv37fo0k4bm1ox28wggvkb7pbtw).

# Goals

## In Scope

- Preserve current functionality without breaking changes
- Consolidate the multiple existing rate limiting options into a single,
  configurable rate limiting solution
- Remove the separate “precise” rate limiter

### Problems to Address  

- High CPU load with default rate limiter
- High lock contention that impacts shared Netty IO threads and adds
  latency to unrelated Pulsar topic producers ([Bug] RateLimiter lock
  contention when use precise publish rate limiter #21442.)
- Multiple limiting implementations (default, precise) which
  unnecessarily expose implementation details to users of Pulsar and
  make the code harder to maintain and improve
- Inability to limit throughput consistently when using default rate
  limiter
- Inconsistent behavior across multiple levels of throttling (broker,
  namespace, connection)
- Code maintainability
  - Improve understandability of code

## Out of Scope

- Custom/pluggable rate limiters
- Additional rate limiting features
- Cluster-wide capacity management
- Addressing the shared connection multiplexing problem where throttling
  multiple independent streams multiplexed on the same connection cannot
  be consistently throttled by pausing reads on the server side.

# High Level Design

The proposed refactor will overhaul rate limiting internals while
preserving existing APIs and user-facing behavior. A token bucket
algorithm will provide efficient and accurate calculations to throttle
throughput. 

Multiple built-in options such as "precise" rate limiter will be
consolidated under a single solution. Performance issues caused by
contention and CPU overhead will be addressed.

## Publisher rate limiter throttling

The refactored design ensures that a publish rate limiter operates in a
non-blocking fashion. It consumes the quota seamlessly without
disrupting ongoing operations. When the quota is exhausted, the
connection is throttled by pausing reads.

Subsequently, the publisher rate limiter adds the throttled producer to
a queue for unthrottling and schedules a task to process this queue
after a certain delay, assuming there isn't a task already scheduled.
When this task is executed, it unthrottles all the publishers in the
queue, provided there is available quota. This queuing mechanism
guarantees fairness in the solution.

In terms of implementation, the rate limiter necessitates a token bucket
algorithm that is asynchronous, lockless, and non-blocking. This
algorithm should be capable of calculating the duration of throttling. A
proof-of-concept implementation that fulfills these requirements can be
found at https://github.com/lhotari/async-tokenbucket.

# Detailed Design

## Proposed Solution

- Use asynchronous token bucket algorithm
  - Efficient for concurrent updates
    - Can be implemented in a lockless, non-blocking way using CAS
      fields. 
  - Conceptually simple
  - Common traffic shaping approach   
- Unify rate limiting implementations
  - Consolidate the multiple built-in rate limiting options like
    "default" and "precise" into a single unified implementation.  
- Improve understandability, code quality and maintainability. 
- Use more non-blocking asynchronous code and get rid of synchronized
  methods which are causing issues such as #21442.
- Fix the inconsistency of multiple levels of throttling by coordinating
  toggling of the Netty autoread state. Use a reference count type of
  pattern to solve this.

### Preserve Public Contracts

- Avoid breaking existing configs, APIs or client functionality.
- Handle through internal refactoring.  

## Public-facing Changes

There are no changes to existing configs, CLI options, monitoring etc.
This PIP is about a large change which includes a major refactoring and
multiple improvements and bug fixes to rate limiting.

# Links

<!--
Updated afterwards
-->
* [Pulsar Community Meeting minutes
  2023/11/23](https://lists.apache.org/thread/y1sqpyv37fo0k4bm1ox28wggvkb7pbtw)
* [Apache Pulsar service level objectives and rate
  limiting](https://codingthestreams.com/pulsar/2023/11/22/pulsar-slos-and-rate-limiting.html)
* Mailing List discussion thread:
  https://lists.apache.org/thread/xzrp2ypggp1oql437tvmkqgfw2b4ft33
* Mailing List voting thread:
* Proposed changes for Pulsar Rate limiting refactoring:
  https://github.com/apache/pulsar/pull/21681
* Proof-of-concept asynchronous token bucket implementation: https://github.com/lhotari/async-tokenbucket