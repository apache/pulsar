<!DOCTYPE html><html lang="zh-TW"><head><meta charSet="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><title>Pulsar configuration · Apache Pulsar</title><meta name="viewport" content="width=device-width"/><meta name="generator" content="Docusaurus"/><meta name="description" content="&lt;style type=&quot;text/css&quot;&gt;"/><meta name="docsearch:version" content="next"/><meta name="docsearch:language" content="zh-TW"/><meta property="og:title" content="Pulsar configuration · Apache Pulsar"/><meta property="og:type" content="website"/><meta property="og:url" content="https://pulsar.incubator.apache.org/"/><meta property="og:description" content="&lt;style type=&quot;text/css&quot;&gt;"/><meta name="twitter:card" content="summary"/><meta name="twitter:image" content="https://pulsar.incubator.apache.org/img/pulsar.svg"/><link rel="shortcut icon" href="/img/pulsar.ico"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/docsearch.js/1/docsearch.min.css"/><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/atom-one-dark.min.css"/><link rel="alternate" type="application/atom+xml" href="https://pulsar.incubator.apache.org/blog/atom.xml" title="Apache Pulsar Blog ATOM Feed"/><link rel="alternate" type="application/rss+xml" href="https://pulsar.incubator.apache.org/blog/feed.xml" title="Apache Pulsar Blog RSS Feed"/><script>
              (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
              (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
              m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
              })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

              ga('create', 'UA-102219959-1', 'auto');
              ga('send', 'pageview');
            </script><link rel="stylesheet" href="/css/code-blocks-buttons.css"/><script type="text/javascript" src="https://buttons.github.io/buttons.js"></script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.0/clipboard.min.js"></script><script type="text/javascript" src="/js/custom.js"></script><script src="/js/scrollSpy.js"></script><link rel="stylesheet" href="/css/main.css"/><script src="/js/codetabs.js"></script></head><body class="sideNavVisible separateOnPageNav"><div class="fixedHeaderContainer"><div class="headerWrapper wrapper"><header><a href="/zh-TW"><img class="logo" src="/img/pulsar.svg" alt="Apache Pulsar"/></a><a href="/zh-TW/versions"><h3>next</h3></a><div class="navigationWrapper navigationSlider"><nav class="slidingNav"><ul class="nav-site nav-site-internal"><li class=""><a href="/docs/zh-TW/next/standalone" target="_self">Docs</a></li><li class=""><a href="/zh-TW/download" target="_self">Download</a></li><li class=""><a href="/docs/zh-TW/next/client-libraries" target="_self">客戶端</a></li><li class=""><a href="#restapis" target="_self">REST APIs</a></li><li class=""><a href="#cli" target="_self">Cli</a></li><li class=""><a href="/blog/" target="_self">Blog</a></li><li class=""><a href="#community" target="_self">Community</a></li><li class=""><a href="#apache" target="_self">Apache</a></li><span><li><a id="languages-menu" href="#"><img class="languages-icon" src="/img/language.svg" alt="Languages icon"/>繁體中文</a><div id="languages-dropdown" class="hide"><ul id="languages-dropdown-items"><li><a href="/docs/en/next/reference-configuration">English</a></li><li><a href="/docs/ja/next/reference-configuration">日本語</a></li><li><a href="/docs/fr/next/reference-configuration">Français</a></li><li><a href="/docs/ko/next/reference-configuration">한국어</a></li><li><a href="/docs/zh-CN/next/reference-configuration">中文</a></li><li><a href="https://crowdin.com/project/apache-pulsar" target="_blank" rel="noreferrer noopener">Help Translate</a></li></ul></div></li><script>
        const languagesMenuItem = document.getElementById("languages-menu");
        const languagesDropDown = document.getElementById("languages-dropdown");
        languagesMenuItem.addEventListener("click", function(event) {
          event.preventDefault();

          if (languagesDropDown.className == "hide") {
            languagesDropDown.className = "visible";
          } else {
            languagesDropDown.className = "hide";
          }
        });
      </script></span><li class="navSearchWrapper reactNavSearchWrapper"><input type="text" id="search_input_react" placeholder="Search" title="Search"/></li></ul></nav></div></header></div></div><div class="navPusher"><div class="docMainWrapper wrapper"><div class="container mainContainer docsContainer"><div class="wrapper"><div class="post"><header class="postHeader"><a class="edit-page-link button" href="https://crowdin.com/project/apache-pulsar/zh-TW" target="_blank" rel="noreferrer noopener">Translate</a><h1 id="__docusaurus" class="postHeaderTitle">Pulsar configuration</h1></header><article><div><span><style type="text/css">
  table{
    font-size: 80%;
  }
</style>
<p>Pulsar configuration can be managed via a series of configuration files contained in the <a href="https://github.com/apache/pulsar/tree/master/conf"><code>conf</code></a> directory of a Pulsar <a href="/docs/zh-TW/next/standalone">installation</a></p>
<ul>
<li><a href="#bookkeeper">BookKeeper</a></li>
<li><a href="#broker">Broker</a></li>
<li><a href="#client">Client</a></li>
<li><a href="#service-discovery">Service discovery</a></li>
<li><a href="#log4j">Log4j</a></li>
<li><a href="#log4j-shell">Log4j shell</a></li>
<li><a href="#standalone">Standalone</a></li>
<li><a href="#websocket">WebSocket</a></li>
<li><a href="#pulsar-proxy">Pulsar proxy</a></li>
<li><a href="#zookeeper">ZooKeeper</a></li>
</ul>
<h2><a class="anchor" aria-hidden="true" id="bookkeeper"></a><a href="#bookkeeper" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>BookKeeper</h2>
<p>BookKeeper is a replicated log storage system that Pulsar uses for durable storage of all messages.</p>
<table>
<thead>
<tr><th>Name</th><th>Description</th><th>Default</th></tr>
</thead>
<tbody>
<tr><td>bookiePort</td><td>The port on which the bookie server listens.</td><td>3181</td></tr>
<tr><td>allowLoopback</td><td>Whether the bookie is allowed to use a loopback interface as its primary interface (i.e. the interface used to establish its identity). By default, loopback interfaces are not allowed as the primary interface. Using a loopback interface as the primary interface usually indicates a configuration error. For example, it’s fairly common in some VPS setups to not configure a hostname or to have the hostname resolve to <code>127.0.0.1</code>. If this is the case, then all bookies in the cluster will establish their identities as <code>127.0.0.1:3181</code> and only one will be able to join the cluster. For VPSs configured like this, you should explicitly set the listening interface.</td><td>false</td></tr>
<tr><td>listeningInterface</td><td>The network interface on which the bookie listens. If not set, the bookie will listen on all interfaces.</td><td>eth0</td></tr>
<tr><td>advertisedAddress</td><td>Configure a specific hostname or IP address that the bookie should use to advertise itself to clients. If not set, bookie will advertised its own IP address or hostname, depending on the <code>listeningInterface</code> and <code>useHostNameAsBookieID</code> settings.</td><td>N/A</td></tr>
<tr><td>allowMultipleDirsUnderSameDiskPartition</td><td>Configure the bookie to allow/disallow multiple ledger/index/journal directories in the same filesystem disk partition</td><td>false</td></tr>
<tr><td>minUsableSizeForIndexFileCreation</td><td>The minimum safe usable size available in index directory for bookie to create index files while replaying journal at the time of bookie starts in Readonly Mode (in bytes).</td><td>1073741824</td></tr>
<tr><td>journalDirectory</td><td>The directory where Bookkeeper outputs its write-ahead log (WAL)</td><td>data/bookkeeper/journal</td></tr>
<tr><td>journalDirectories</td><td>Directories that BookKeeper outputs its write ahead log. Multi directories are available, being separated by <code>,</code>. For example: <code>journalDirectories=/tmp/bk-journal1,/tmp/bk-journal2</code>. If <code>journalDirectories</code> is set, bookies will skip <code>journalDirectory</code> and use this setting directory.</td><td>/tmp/bk-journal</td></tr>
<tr><td>ledgerDirectories</td><td>The directory where Bookkeeper outputs ledger snapshots. This could define multiple directories to store snapshots separated by comma, for example <code>ledgerDirectories=/tmp/bk1-data,/tmp/bk2-data</code>. Ideally, ledger dirs and the journal dir are each in a different device, which reduces the contention between random I/O and sequential write. It is possible to run with a single disk, but performance will be significantly lower.</td><td>data/bookkeeper/ledgers</td></tr>
<tr><td>ledgerManagerType</td><td>The type of ledger manager used to manage how ledgers are stored, managed, and garbage collected. See <a href="http://bookkeeper.apache.org/docs/latest/getting-started/concepts">BookKeeper Internals</a> for more info.</td><td>hierarchical</td></tr>
<tr><td>zkLedgersRootPath</td><td>The root ZooKeeper path used to store ledger metadata. This parameter is used by the ZooKeeper-based ledger manager as a root znode to store all ledgers.</td><td>/ledgers</td></tr>
<tr><td>ledgerStorageClass</td><td>Ledger storage implementation class</td><td>org.apache.bookkeeper.bookie.storage.ldb.DbLedgerStorage</td></tr>
<tr><td>entryLogFilePreallocationEnabled</td><td>Enable or disable entry logger preallocation</td><td>true</td></tr>
<tr><td>logSizeLimit</td><td>Max file size of the entry logger, in bytes. A new entry log file will be created when the old one reaches the file size limitation.</td><td>2147483648</td></tr>
<tr><td>minorCompactionThreshold</td><td>Threshold of minor compaction. Entry log files whose remaining size percentage reaches below this threshold will be compacted in a minor compaction. If set to less than zero, the minor compaction is disabled.</td><td>0.2</td></tr>
<tr><td>minorCompactionInterval</td><td>Time interval to run minor compaction, in seconds. If set to less than zero, the minor compaction is disabled. Note: should be greater than gcWaitTime.</td><td>3600</td></tr>
<tr><td>majorCompactionThreshold</td><td>The threshold of major compaction. Entry log files whose remaining size percentage reaches below this threshold will be compacted in a major compaction. Those entry log files whose remaining size percentage is still higher than the threshold will never be compacted. If set to less than zero, the minor compaction is disabled.</td><td>0.5</td></tr>
<tr><td>majorCompactionInterval</td><td>The time interval to run major compaction, in seconds. If set to less than zero, the major compaction is disabled. Note: should be greater than gcWaitTime.</td><td>86400</td></tr>
<tr><td>readOnlyModeEnabled</td><td>If <code>readOnlyModeEnabled=true</code>, then on all full ledger disks, bookie will be converted to read-only mode and serve only read requests. Otherwise the bookie will be shutdown.</td><td>true</td></tr>
<tr><td>forceReadOnlyBookie</td><td>Whether the bookie is force started in read only mode.</td><td>false</td></tr>
<tr><td>persistBookieStatusEnabled</td><td>Persist the bookie status locally on the disks. So the bookies can keep their status upon restarts.</td><td>false</td></tr>
<tr><td>compactionMaxOutstandingRequests</td><td>Sets the maximum number of entries that can be compacted without flushing. When compacting, the entries are written to the entrylog and the new offsets are cached in memory. Once the entrylog is flushed the index is updated with the new offsets. This parameter controls the number of entries added to the entrylog before a flush is forced. A higher value for this parameter means more memory will be used for offsets. Each offset consists of 3 longs. This parameter should not be modified unless you’re fully aware of the consequences.</td><td>100000</td></tr>
<tr><td>compactionRate</td><td>The rate at which compaction will read entries, in adds per second.</td><td>1000</td></tr>
<tr><td>isThrottleByBytes</td><td>Throttle compaction by bytes or by entries.</td><td>false</td></tr>
<tr><td>compactionRateByEntries</td><td>The rate at which compaction will read entries, in adds per second.</td><td>1000</td></tr>
<tr><td>compactionRateByBytes</td><td>Set the rate at which compaction will readd entries. The unit is bytes added per second.</td><td>1000000</td></tr>
<tr><td>journalMaxSizeMB</td><td>Max file size of journal file, in megabytes. A new journal file will be created when the old one reaches the file size limitation.</td><td>2048</td></tr>
<tr><td>journalMaxBackups</td><td>The max number of old journal filse to keep. Keeping a number of old journal files would help data recovery in special cases.</td><td>5</td></tr>
<tr><td>journalPreAllocSizeMB</td><td>How space to pre-allocate at a time in the journal.</td><td>16</td></tr>
<tr><td>journalWriteBufferSizeKB</td><td>The of the write buffers used for the journal.</td><td>64</td></tr>
<tr><td>journalRemoveFromPageCache</td><td>Whether pages should be removed from the page cache after force write.</td><td>true</td></tr>
<tr><td>journalAdaptiveGroupWrites</td><td>Whether to group journal force writes, which optimizes group commit for higher throughput.</td><td>true</td></tr>
<tr><td>journalMaxGroupWaitMSec</td><td>The maximum latency to impose on a journal write to achieve grouping.</td><td>1</td></tr>
<tr><td>journalAlignmentSize</td><td>All the journal writes and commits should be aligned to given size</td><td>4096</td></tr>
<tr><td>journalBufferedWritesThreshold</td><td>Maximum writes to buffer to achieve grouping</td><td>524288</td></tr>
<tr><td>journalFlushWhenQueueEmpty</td><td>If we should flush the journal when journal queue is empty</td><td>false</td></tr>
<tr><td>numJournalCallbackThreads</td><td>The number of threads that should handle journal callbacks</td><td>8</td></tr>
<tr><td>openLedgerRereplicationGracePeriod</td><td>The grace period, in milliseconds, that the replication worker waits before fencing and replicating a ledger fragment that's still being written to upon bookie failure.</td><td>30000</td></tr>
<tr><td>rereplicationEntryBatchSize</td><td>The number of max entries to keep in fragment for re-replication</td><td>100</td></tr>
<tr><td>autoRecoveryDaemonEnabled</td><td>Whether the bookie itself can start auto-recovery service.</td><td>true</td></tr>
<tr><td>lostBookieRecoveryDelay</td><td>How long to wait, in seconds, before starting auto recovery of a lost bookie.</td><td>0</td></tr>
<tr><td>gcWaitTime</td><td>How long the interval to trigger next garbage collection, in milliseconds. Since garbage collection is running in background, too frequent gc will heart performance. It is better to give a higher number of gc interval if there is enough disk capacity.</td><td>900000</td></tr>
<tr><td>gcOverreplicatedLedgerWaitTime</td><td>How long the interval to trigger next garbage collection of overreplicated ledgers, in milliseconds. This should not be run very frequently since we read the metadata for all the ledgers on the bookie from zk.</td><td>86400000</td></tr>
<tr><td>flushInterval</td><td>How long the interval to flush ledger index pages to disk, in milliseconds. Flushing index files will introduce much random disk I/O. If separating journal dir and ledger dirs each on different devices, flushing would not affect performance. But if putting journal dir and ledger dirs on same device, performance degrade significantly on too frequent flushing. You can consider increment flush interval to get better performance, but you need to pay more time on bookie server restart after failure.</td><td>60000</td></tr>
<tr><td>bookieDeathWatchInterval</td><td>Interval to watch whether bookie is dead or not, in milliseconds</td><td>1000</td></tr>
<tr><td>allowStorageExpansion</td><td>Allow the bookie storage to expand. Newly added ledger and index dirs must be empty.</td><td>false</td></tr>
<tr><td>zkServers</td><td>A list of one of more servers on which zookeeper is running. The server list can be comma separated values, for example: zkServers=zk1:2181,zk2:2181,zk3:2181.</td><td>localhost:2181</td></tr>
<tr><td>zkTimeout</td><td>ZooKeeper client session timeout in milliseconds Bookie server will exit if it received SESSION_EXPIRED because it was partitioned off from ZooKeeper for more than the session timeout JVM garbage collection, disk I/O will cause SESSION_EXPIRED. Increment this value could help avoiding this issue</td><td>30000</td></tr>
<tr><td>zkRetryBackoffStartMs</td><td>The start time that the Zookeeper client backoff retries in milliseconds.</td><td>1000</td></tr>
<tr><td>zkRetryBackoffMaxMs</td><td>The maximum time that the Zookeeper client backoff retries in milliseconds.</td><td>10000</td></tr>
<tr><td>zkEnableSecurity</td><td>Set ACLs on every node written on ZooKeeper, allowing users to read and write BookKeeper metadata stored on ZooKeeper. In order to make ACLs work you need to setup ZooKeeper JAAS authentication. All the bookies and Client need to share the same user, and this is usually done using Kerberos authentication. See ZooKeeper documentation.</td><td>false</td></tr>
<tr><td>httpServerEnabled</td><td>The flag enables/disables starting the admin http server.</td><td>false</td></tr>
<tr><td>httpServerPort</td><td>The http server port to listen on. By default, the value is 8080. Use <code>8000</code> as the port to keep it consistent with prometheus stats provider.</td><td>8000</td></tr>
<tr><td>httpServerClass</td><td>The http server class.</td><td>org.apache.bookkeeper.http.vertx.VertxHttpServer</td></tr>
<tr><td>serverTcpNoDelay</td><td>This settings is used to enabled/disabled Nagle’s algorithm, which is a means of improving the efficiency of TCP/IP networks by reducing the number of packets that need to be sent over the network. If you are sending many small messages, such that more than one can fit in a single IP packet, setting server.tcpnodelay to false to enable Nagle algorithm can provide better performance.</td><td>true</td></tr>
<tr><td>serverSockKeepalive</td><td>This setting is used to send keep-alive messages on connection-oriented sockets.</td><td>true</td></tr>
<tr><td>serverTcpLinger</td><td>The socket linger timeout on close. When enabled, a close or shutdown will not return until all queued messages for the socket have been successfully sent or the linger timeout has been reached. Otherwise, the call returns immediately and the closing is done in the background.</td><td>0</td></tr>
<tr><td>byteBufAllocatorSizeMax</td><td>The maximum buf size of the received ByteBuf allocator.</td><td>1048576</td></tr>
<tr><td>nettyMaxFrameSizeBytes</td><td>The maximum netty frame size in bytes. Any message received larger than this will be rejected. The default value is 1G.</td><td>5253120</td></tr>
<tr><td>openFileLimit</td><td>Max number of ledger index files could be opened in bookie server If number of ledger index files reaches this limitation, bookie server started to swap some ledgers from memory to disk. Too frequent swap will affect performance. You can tune this number to gain performance according your requirements.</td><td>0</td></tr>
<tr><td>pageSize</td><td>Size of a index page in ledger cache, in bytes A larger index page can improve performance writing page to disk, which is efficient when you have small number of ledgers and these ledgers have similar number of entries. If you have large number of ledgers and each ledger has fewer entries, smaller index page would improve memory usage.</td><td>8192</td></tr>
<tr><td>pageLimit</td><td>How many index pages provided in ledger cache If number of index pages reaches this limitation, bookie server starts to swap some ledgers from memory to disk. You can increment this value when you found swap became more frequent. But make sure pageLimit*pageSize should not more than JVM max memory limitation, otherwise you would got OutOfMemoryException. In general, incrementing pageLimit, using smaller index page would gain better performance in lager number of ledgers with fewer entries case If pageLimit is -1, bookie server will use 1/3 of JVM memory to compute the limitation of number of index pages.</td><td>0</td></tr>
<tr><td>readOnlyModeEnabled</td><td>If all ledger directories configured are full, then support only read requests for clients. If “readOnlyModeEnabled=true” then on all ledger disks full, bookie will be converted to read-only mode and serve only read requests. Otherwise the bookie will be shutdown. By default this will be disabled.</td><td>true</td></tr>
<tr><td>diskUsageThreshold</td><td>For each ledger dir, maximum disk space which can be used. Default is 0.95f. i.e. 95% of disk can be used at most after which nothing will be written to that partition. If all ledger dir partitions are full, then bookie will turn to readonly mode if ‘readOnlyModeEnabled=true’ is set, else it will shutdown. Valid values should be in between 0 and 1 (exclusive).</td><td>0.95</td></tr>
<tr><td>diskCheckInterval</td><td>Disk check interval in milli seconds, interval to check the ledger dirs usage.</td><td>10000</td></tr>
<tr><td>auditorPeriodicCheckInterval</td><td>Interval at which the auditor will do a check of all ledgers in the cluster. By default this runs once a week. The interval is set in seconds. To disable the periodic check completely, set this to 0. Note that periodic checking will put extra load on the cluster, so it should not be run more frequently than once a day.</td><td>604800</td></tr>
<tr><td>sortedLedgerStorageEnabled</td><td>Whether sorted-ledger storage is enabled.</td><td>ture</td></tr>
<tr><td>auditorPeriodicBookieCheckInterval</td><td>The interval between auditor bookie checks. The auditor bookie check, checks ledger metadata to see which bookies should contain entries for each ledger. If a bookie which should contain entries is unavailable, thea the ledger containing that entry is marked for recovery. Setting this to 0 disabled the periodic check. Bookie checks will still run when a bookie fails. The interval is specified in seconds.</td><td>86400</td></tr>
<tr><td>numAddWorkerThreads</td><td>The number of threads that should handle write requests. if zero, the writes would be handled by netty threads directly.</td><td>0</td></tr>
<tr><td>numReadWorkerThreads</td><td>The number of threads that should handle read requests. if zero, the reads would be handled by netty threads directly.</td><td>8</td></tr>
<tr><td>numHighPriorityWorkerThreads</td><td>The umber of threads that should be used for high priority requests (i.e. recovery reads and adds, and fencing).</td><td>8</td></tr>
<tr><td>maxPendingReadRequestsPerThread</td><td>If read workers threads are enabled, limit the number of pending requests, to avoid the executor queue to grow indefinitely.</td><td>2500</td></tr>
<tr><td>maxPendingAddRequestsPerThread</td><td>The limited number of pending requests, which is used to avoid the executor queue to grow indefinitely when add workers threads are enabled.</td><td>10000</td></tr>
<tr><td>isForceGCAllowWhenNoSpace</td><td>Whether force compaction is allowed when the disk is full or almost full. Forcing GC could get some space back, but could also fill up the disk space more quickly. This is because new log files are created before GC, while old garbage log files are deleted after GC.</td><td>false</td></tr>
<tr><td>verifyMetadataOnGC</td><td>True if the bookie should double check <code>readMetadata</code> prior to GC.</td><td>false</td></tr>
<tr><td>flushEntrylogBytes</td><td>Entry log flush interval in bytes. Flushing in smaller chunks but more frequently reduces spikes in disk I/O. Flushing too frequently may also affect performance negatively.</td><td>268435456</td></tr>
<tr><td>readBufferSizeBytes</td><td>The number of bytes we should use as capacity for BufferedReadChannel.</td><td>4096</td></tr>
<tr><td>writeBufferSizeBytes</td><td>The number of bytes used as capacity for the write buffer</td><td>65536</td></tr>
<tr><td>useHostNameAsBookieID</td><td>Whether the bookie should use its hostname to register with the coordination service (e.g.: zookeeper service). When false, bookie will use its ip address for the registration.</td><td>false</td></tr>
<tr><td>allowEphemeralPorts</td><td>Whether the bookie is allowed to use an ephemeral port (port 0) as its server port. By default, an ephemeral port is not allowed. Using an ephemeral port as the service port usually indicates a configuration error. However, in unit tests, using an ephemeral port will address port conflict problems and allow running tests in parallel.</td><td>false</td></tr>
<tr><td>enableLocalTransport</td><td>Whether the bookie is allowed to listen for the BookKeeper clients executed on the local JVM.</td><td>false</td></tr>
<tr><td>disableServerSocketBind</td><td>Whether the bookie is allowed to disable bind on network interfaces. This bookie will be available only to BookKeeper clients executed on the local JVM.</td><td>false</td></tr>
<tr><td>skipListArenaChunkSize</td><td>The number of bytes that we should use as chunk allocation for <code>org.apache.bookkeeper.bookie.SkipListArena</code>.</td><td>4194304</td></tr>
<tr><td>skipListArenaMaxAllocSize</td><td>The maximum size that we should allocate from the skiplist arena. Allocations larger than this should be allocated directly by the VM to avoid fragmentation.</td><td>131072</td></tr>
<tr><td>bookieAuthProviderFactoryClass</td><td>The factory class name of the bookie authentication provider. If this is null, then there is no authentication.</td><td>null</td></tr>
<tr><td>statsProviderClass</td><td></td><td>org.apache.bookkeeper.stats.prometheus.PrometheusMetricsProvider</td></tr>
<tr><td>prometheusStatsHttpPort</td><td></td><td>8000</td></tr>
<tr><td>dbStorage_writeCacheMaxSizeMb</td><td>Size of Write Cache. Memory is allocated from JVM direct memory. Write cache is used to buffer entries before flushing into the entry log. For good performance, it should be big enough to hold a substantial amount of entries in the flush interval. By default, it is allocated to 25% of the available direct memory.</td><td>N/A</td></tr>
<tr><td>dbStorage_readAheadCacheMaxSizeMb</td><td>Size of Read cache. Memory is allocated from JVM direct memory. This read cache is pre-filled doing read-ahead whenever a cache miss happens. By default, it is allocated to 25% of the available direct memory.</td><td>N/A</td></tr>
<tr><td>dbStorage_readAheadCacheBatchSize</td><td>How many entries to pre-fill in cache after a read cache miss</td><td>1000</td></tr>
<tr><td>dbStorage_rocksDB_blockCacheSize</td><td>Size of RocksDB block-cache. For best performance, this cache should be big enough to hold a significant portion of the index database which can reach ~2GB in some cases. By default, it uses 10% of direct memory.</td><td>N/A</td></tr>
<tr><td>dbStorage_rocksDB_writeBufferSizeMB</td><td></td><td>64</td></tr>
<tr><td>dbStorage_rocksDB_sstSizeInMB</td><td></td><td>64</td></tr>
<tr><td>dbStorage_rocksDB_blockSize</td><td></td><td>65536</td></tr>
<tr><td>dbStorage_rocksDB_bloomFilterBitsPerKey</td><td></td><td>10</td></tr>
<tr><td>dbStorage_rocksDB_numLevels</td><td></td><td>-1</td></tr>
<tr><td>dbStorage_rocksDB_numFilesInLevel0</td><td></td><td>4</td></tr>
<tr><td>dbStorage_rocksDB_maxSizeInLevel1MB</td><td></td><td>256</td></tr>
<tr><td>nettyMaxFrameSizeBytes</td><td>Set the maximum netty frame size in bytes. If the size of a received message is larger than the configured value, the message is rejected.</td><td>1 GB</td></tr>
</tbody>
</table>
<h2><a class="anchor" aria-hidden="true" id="broker"></a><a href="#broker" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Broker</h2>
<p>Pulsar brokers are responsible for handling incoming messages from producers, dispatching messages to consumers, replicating data between clusters, and more.</p>
<p>|Name|Description|Default| |---|---|---| |advertisedListeners|Specify multiple advertised listeners for the broker.</p>
<p>The format is <code>&lt;listener_name&gt;:pulsar://&lt;host&gt;:&lt;port&gt;</code>.</p>
<p>If there are multiple listeners, separate them with commas.</p>
<p><strong>Note</strong>: do not use this configuration with <code>advertisedAddress</code> and <code>brokerServicePort</code>. If the value of this configuration is empty, the broker uses <code>advertisedAddress</code> and <code>brokerServicePort</code>|/| internalListenerName|Specify the internal listener name for the broker.</p>
<p><strong>Note</strong>: the listener name must be contained in <code>advertisedListeners</code>.</p>
<p>If the value of this configuration is empty, the broker uses the first listener as the internal listener.|/| |authenticateOriginalAuthData| If this flag is set to <code>true</code>, the broker authenticates the original Auth data; else it just accepts the originalPrincipal and authorizes it (if required). |false| |enablePersistentTopics| Whether persistent topics are enabled on the broker |true| |enableNonPersistentTopics| Whether non-persistent topics are enabled on the broker |true| |functionsWorkerEnabled| Whether the Pulsar Functions worker service is enabled in the broker |false| |exposePublisherStats|Whether to enable topic level metrics.|true| |statsUpdateFrequencyInSecs||60| |statsUpdateInitialDelayInSecs||60| |zookeeperServers| Zookeeper quorum connection string || |zooKeeperCacheExpirySeconds|ZooKeeper cache expiry time in seconds|300 |configurationStoreServers| Configuration store connection string (as a comma-separated list) || |brokerServicePort| Broker data port |6650| |brokerServicePortTls| Broker data port for TLS |6651| |webServicePort| Port to use to server HTTP request |8080| |webServicePortTls| Port to use to server HTTPS request |8443| |webSocketServiceEnabled| Enable the WebSocket API service in broker |false| |webSocketNumIoThreads|The number of IO threads in Pulsar Client used in WebSocket proxy.|8| |webSocketConnectionsPerBroker|The number of connections per Broker in Pulsar Client used in WebSocket proxy.|8| |webSocketSessionIdleTimeoutMillis|Time in milliseconds that idle WebSocket session times out.|300000| |webSocketMaxTextFrameSize|The maximum size of a text message during parsing in WebSocket proxy.|1048576| |exposeTopicLevelMetricsInPrometheus|Whether to enable topic level metrics.|true| |exposeConsumerLevelMetricsInPrometheus|Whether to enable consumer level metrics.|false| |jvmGCMetricsLoggerClassName|Classname of Pluggable JVM GC metrics logger that can log GC specific metrics.|N/A| |bindAddress| Hostname or IP address the service binds on, default is 0.0.0.0. |0.0.0.0| |advertisedAddress| Hostname or IP address the service advertises to the outside world. If not set, the value of <code>InetAddress.getLocalHost().getHostName()</code> is used. || |clusterName| Name of the cluster to which this broker belongs to || |brokerDeduplicationEnabled| Sets the default behavior for message deduplication in the broker. If enabled, the broker will reject messages that were already stored in the topic. This setting can be overridden on a per-namespace basis. |false| |brokerDeduplicationMaxNumberOfProducers| The maximum number of producers for which information will be stored for deduplication purposes. |10000| |brokerDeduplicationEntriesInterval| The number of entries after which a deduplication informational snapshot is taken. A larger interval will lead to fewer snapshots being taken, though this would also lengthen the topic recovery time (the time required for entries published after the snapshot to be replayed). |1000| |brokerDeduplicationProducerInactivityTimeoutMinutes| The time of inactivity (in minutes) after which the broker will discard deduplication information related to a disconnected producer. |360| |dispatchThrottlingRatePerReplicatorInMsg| The default messages per second dispatch throttling-limit for every replicator in replication. The value of <code>0</code> means disabling replication message dispatch-throttling| 0 | |dispatchThrottlingRatePerReplicatorInByte| The default bytes per second dispatch throttling-limit for every replicator in replication. The value of <code>0</code> means disabling replication message-byte dispatch-throttling| 0 | |zooKeeperSessionTimeoutMillis| Zookeeper session timeout in milliseconds |30000| |brokerShutdownTimeoutMs| Time to wait for broker graceful shutdown. After this time elapses, the process will be killed |60000| |skipBrokerShutdownOnOOM| Flag to skip broker shutdown when broker handles Out of memory error. |false| |backlogQuotaCheckEnabled| Enable backlog quota check. Enforces action on topic when the quota is reached |true| |backlogQuotaCheckIntervalInSeconds| How often to check for topics that have reached the quota |60| |backlogQuotaDefaultLimitGB| The default per-topic backlog quota limit. Being less than 0 means no limitation. By default, it is -1. | -1 | |backlogQuotaDefaultRetentionPolicy|The defaulted backlog quota retention policy. By Default, it is <code>producer_request_hold</code>.</p>
<ul>
<li><p>'producer_request_hold' Policy which holds producer's send request until the resource becomes available (or holding times out)</p></li>
<li><p>'producer_exception' Policy which throws <code>javax.jms.ResourceAllocationException</code> to the producer</p></li>
<li><p>'consumer_backlog_eviction' Policy which evicts the oldest message from the slowest consumer's backlog|producer_request_hold| |allowAutoTopicCreation| Enable topic auto creation if a new producer or consumer connected |true| |allowAutoTopicCreationType| The type of topic that is allowed to be automatically created.(partitioned/non-partitioned) |non-partitioned| |allowAutoSubscriptionCreation| Enable subscription auto creation if a new consumer connected |true| |defaultNumPartitions| The number of partitioned topics that is allowed to be automatically created if
<code>allowAutoTopicCreationType</code> is partitioned |1| |brokerDeleteInactiveTopicsEnabled| Enable the deletion of inactive topics |true| |brokerDeleteInactiveTopicsFrequencySeconds| How often to check for inactive topics |60| | brokerDeleteInactiveTopicsMode | Set the mode to delete inactive topics.</p></li>
<li><p><code>delete_when_no_subscriptions</code>: delete the topic which has no subscriptions or active producers.</p>
<ul>
<li><p><code>delete_when_subscriptions_caught_up</code>: delete the topic whose subscriptions have no backlogs and which has no active producers or consumers. | <code>delete_when_no_subscriptions</code> | | brokerDeleteInactiveTopicsMaxInactiveDurationSeconds | Set the maximum duration for inactive topics. If it is not specified, the <code>brokerDeleteInactiveTopicsFrequencySeconds</code> parameter is adopted. | N/A | |messageExpiryCheckIntervalInMinutes| How frequently to proactively check and purge expired messages |5| |brokerServiceCompactionMonitorIntervalInSeconds| Interval between checks to see if topics with compaction policies need to be compacted |60| |delayedDeliveryEnabled|Whether to enable the delayed delivery for messages. If disabled, messages will be immediately delivered and there will be no tracking overhead.|true| |delayedDeliveryTickTimeMillis|Control the tick time for retrying on delayed delivery, which affecte the accuracy of the delivery time compared to the scheduled time. By default, it is 1 second.|1000| |activeConsumerFailoverDelayTimeMillis| How long to delay rewinding cursor and dispatching messages when active consumer is changed. |1000| |clientLibraryVersionCheckEnabled| Enable check for minimum allowed client library version |false| |clientLibraryVersionCheckAllowUnversioned| Allow client libraries with no version information |true| |statusFilePath| Path for the file used to determine the rotation status for the broker when responding to service discovery health checks || |preferLaterVersions| If true, (and ModularLoadManagerImpl is being used), the load manager will attempt to use only brokers running the latest software version (to minimize impact to bundles) |false| |maxNumPartitionsPerPartitionedTopic|Max number of partitions per partitioned topic. Use 0 or negative number to disable the check|0| |tlsEnabled|Deprecated - Use <code>webServicePortTls</code> and <code>brokerServicePortTls</code> instead. |false| |tlsCertificateFilePath| Path for the TLS certificate file || |tlsKeyFilePath| Path for the TLS private key file || |tlsTrustCertsFilePath| Path for the trusted TLS certificate file. This cert is used to verify that any certs presented by connecting clients are signed by a certificate authority. If this verification fails, then the certs are untrusted and the connections are dropped. || |tlsAllowInsecureConnection| Accept untrusted TLS certificate from client. If it is set to <code>true</code>, a client with a cert which cannot be verified with the 'tlsTrustCertsFilePath' cert will be allowed to connect to the server, though the cert will not be used for client authentication. |false| |tlsProtocols|Specify the tls protocols the broker will use to negotiate during TLS Handshake. Multiple values can be specified, separated by commas. Example:- <code>TLSv1.2</code>, <code>TLSv1.1</code>, <code>TLSv1</code> || |tlsCiphers|Specify the tls cipher the broker will use to negotiate during TLS Handshake. Multiple values can be specified, separated by commas. Example:- <code>TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256</code>|| |tlsEnabledWithKeyStore| Enable TLS with KeyStore type configuration in broker |false| |tlsProvider| TLS Provider for KeyStore type || |tlsKeyStoreType| LS KeyStore type configuration in broker: JKS, PKCS12 |JKS| |tlsKeyStore| TLS KeyStore path in broker || |tlsKeyStorePassword| TLS KeyStore password for broker || |brokerClientTlsEnabledWithKeyStore| Whether internal client use KeyStore type to authenticate with Pulsar brokers |false| |brokerClientSslProvider| The TLS Provider used by internal client to authenticate with other Pulsar brokers || |brokerClientTlsTrustStoreType| TLS TrustStore type configuration for internal client: JKS, PKCS12, used by the internal client to authenticate with Pulsar brokers |JKS| |brokerClientTlsTrustStore| TLS TrustStore path for internal client, used by the internal client to authenticate with Pulsar brokers || |brokerClientTlsTrustStorePassword| TLS TrustStore password for internal client, used by the internal client to authenticate with Pulsar brokers || |brokerClientTlsCiphers| Specify the tls cipher the internal client will use to negotiate during TLS Handshake. (a comma-separated list of ciphers) e.g. [TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256]|| |brokerClientTlsProtocols|Specify the tls protocols the broker will use to negotiate during TLS handshake. (a comma-separated list of protocol names). e.g. [TLSv1.2, TLSv1.1, TLSv1] || |ttlDurationDefaultInSeconds| The default ttl for namespaces if ttl is not configured at namespace policies. |0| |tokenSecretKey| Configure the secret key to be used to validate auth tokens. The key can be specified like: <code>tokenSecretKey=data:;base64,xxxxxxxxx</code> or <code>tokenSecretKey=file:///my/secret.key</code>|| |tokenPublicKey| Configure the public key to be used to validate auth tokens. The key can be specified like: <code>tokenPublicKey=data:;base64,xxxxxxxxx</code> or <code>tokenPublicKey=file:///my/secret.key</code>|| |tokenPublicAlg| Configure the algorithm to be used to validate auth tokens. This can be any of the asymettric algorithms supported by Java JWT (<a href="https://github.com/jwtk/jjwt#signature-algorithms-keys">https://github.com/jwtk/jjwt#signature-algorithms-keys</a>) |RS256| |tokenAuthClaim| Specify which of the token's claims will be used as the authentication &quot;principal&quot; or &quot;role&quot;. The default &quot;sub&quot; claim will be used if this is left blank || |tokenAudienceClaim| The token audience &quot;claim&quot; name, e.g. &quot;aud&quot;, that will be used to get the audience from token. If not set, audience will not be verified. || |tokenAudience| The token audience stands for this broker. The field <code>tokenAudienceClaim</code> of a valid token, need contains this. || |maxUnackedMessagesPerConsumer| Max number of unacknowledged messages allowed to receive messages by a consumer on a shared subscription. Broker will stop sending messages to consumer once, this limit reaches until consumer starts acknowledging messages back. Using a value of 0, is disabling unackeMessage limit check and consumer can receive messages without any restriction |50000| |maxUnackedMessagesPerSubscription| Max number of unacknowledged messages allowed per shared subscription. Broker will stop dispatching messages to all consumers of the subscription once this limit reaches until consumer starts acknowledging messages back and unack count reaches to limit/2. Using a value of 0, is disabling unackedMessage-limit check and dispatcher can dispatch messages without any restriction |200000| |subscriptionRedeliveryTrackerEnabled| Enable subscription message redelivery tracker |true| subscriptionExpirationTimeMinutes | How long to delete inactive subscriptions from last consuming.</p>
<p>Setting this configuration to a value <strong>greater than 0</strong> deletes inactive subscriptions automatically.<br>
Setting this configuration to <strong>0</strong> does not delete inactive subscriptions automatically.</p>
<p>Since this configuration takes effect on all topics, if there is even one topic whose subscriptions should not be deleted automatically, you need to set it to 0.<br>
Instead, you can set a subscription expiration time for each <strong>namespace</strong> using the <a href="http://pulsar.apache.org/tools/pulsar-admin/2.6.0-SNAPSHOT/#-em-set-subscription-expiration-time-em-"><code>pulsar-admin namespaces set-subscription-expiration-time options</code> command</a>. | 0 | |maxConcurrentLookupRequest| Max number of concurrent lookup request broker allows to throttle heavy incoming lookup traffic |50000| |maxConcurrentTopicLoadRequest| Max number of concurrent topic loading request broker allows to control number of zk-operations |5000| |authenticationEnabled| Enable authentication |false| |authenticationProviders| Autentication provider name list, which is comma separated list of class names || | authenticationRefreshCheckSeconds | Interval of time for checking for expired authentication credentials | 60 | |authorizationEnabled| Enforce authorization |false| |superUserRoles| Role names that are treated as “super-user”, meaning they will be able to do all admin operations and publish/consume from all topics || |brokerClientAuthenticationPlugin| Authentication settings of the broker itself. Used when the broker connects to other brokers, either in same or other clusters || |brokerClientAuthenticationParameters||| |athenzDomainNames| Supported Athenz provider domain names(comma separated) for authentication || |exposePreciseBacklogInPrometheus| Enable expose the precise backlog stats, set false to use published counter and consumed counter to calculate, this would be more efficient but may be inaccurate. |false| |schemaRegistryStorageClassName|The schema storage implementation used by this broker.|org.apache.pulsar.broker.service.schema.BookkeeperSchemaStorageFactory| |isSchemaValidationEnforced|Enforce schema validation on following cases: if a producer without a schema attempts to produce to a topic with schema, the producer will be failed to connect. PLEASE be carefully on using this, since non-java clients don't support schema. If this setting is enabled, then non-java clients fail to produce.|false| |offloadersDirectory|The directory for all the offloader implementations.|./offloaders| |bookkeeperMetadataServiceUri| Metadata service uri that bookkeeper is used for loading corresponding metadata driver and resolving its metadata service location. This value can be fetched using <code>bookkeeper shell whatisinstanceid</code> command in BookKeeper cluster. For example: <a href="zk+hierarchical://localhost:2181/ledgers">zk+hierarchical://localhost:2181/ledgers</a>. The metadata service uri list can also be semicolon separated values like below: <a href="zk+hierarchical://zk1:2181">zk+hierarchical://zk1:2181</a>;zk2:2181;zk3:2181/ledgers || |bookkeeperClientAuthenticationPlugin| Authentication plugin to use when connecting to bookies || |bookkeeperClientAuthenticationParametersName| BookKeeper auth plugin implementatation specifics parameters name and values || |bookkeeperClientAuthenticationParameters||| |bookkeeperClientTimeoutInSeconds| Timeout for BK add / read operations |30| |bookkeeperClientSpeculativeReadTimeoutInMillis| Speculative reads are initiated if a read request doesn’t complete within a certain time Using a value of 0, is disabling the speculative reads |0| |bookkeeperClientHealthCheckEnabled| Enable bookies health check. Bookies that have more than the configured number of failure within the interval will be quarantined for some time. During this period, new ledgers won’t be created on these bookies |true| |bookkeeperClientHealthCheckIntervalSeconds||60| |bookkeeperClientHealthCheckErrorThresholdPerInterval||5| |bookkeeperClientHealthCheckQuarantineTimeInSeconds ||1800| |bookkeeperClientRackawarePolicyEnabled| Enable rack-aware bookie selection policy. BK will chose bookies from different racks when forming a new bookie ensemble |true| |bookkeeperClientRegionawarePolicyEnabled| Enable region-aware bookie selection policy. BK will chose bookies from different regions and racks when forming a new bookie ensemble. If enabled, the value of bookkeeperClientRackawarePolicyEnabled is ignored |false| |bookkeeperClientMinNumRacksPerWriteQuorum| Minimum number of racks per write quorum. BK rack-aware bookie selection policy will try to get bookies from at least 'bookkeeperClientMinNumRacksPerWriteQuorum' racks for a write quorum. |2| |bookkeeperClientEnforceMinNumRacksPerWriteQuorum| Enforces rack-aware bookie selection policy to pick bookies from 'bookkeeperClientMinNumRacksPerWriteQuorum' racks for a writeQuorum. If BK can't find bookie then it would throw BKNotEnoughBookiesException instead of picking random one. |false| |bookkeeperClientReorderReadSequenceEnabled| Enable/disable reordering read sequence on reading entries. |false| |bookkeeperClientIsolationGroups| Enable bookie isolation by specifying a list of bookie groups to choose from. Any bookie outside the specified groups will not be used by the broker || |bookkeeperClientSecondaryIsolationGroups| Enable bookie secondary-isolation group if bookkeeperClientIsolationGroups doesn't have enough bookie available. || |bookkeeperClientMinAvailableBookiesInIsolationGroups| Minimum bookies that should be available as part of bookkeeperClientIsolationGroups else broker will include bookkeeperClientSecondaryIsolationGroups bookies in isolated list. || |bookkeeperClientGetBookieInfoIntervalSeconds| Set the interval to periodically check bookie info |86400| |bookkeeperClientGetBookieInfoRetryIntervalSeconds| Set the interval to retry a failed bookie info lookup |60| |bookkeeperEnableStickyReads | Enable/disable having read operations for a ledger to be sticky to a single bookie. If this flag is enabled, the client will use one single bookie (by preference) to read all entries for a ledger. | true | |managedLedgerDefaultEnsembleSize| Number of bookies to use when creating a ledger |2| |managedLedgerDefaultWriteQuorum| Number of copies to store for each message |2| |managedLedgerDefaultAckQuorum| Number of guaranteed copies (acks to wait before write is complete) |2| |managedLedgerCacheSizeMB| Amount of memory to use for caching data payload in managed ledger. This memory is allocated from JVM direct memory and it’s shared across all the topics running in the same broker. By default, uses 1/5th of available direct memory || |managedLedgerCacheCopyEntries| Whether we should make a copy of the entry payloads when inserting in cache| false| |managedLedgerCacheEvictionWatermark| Threshold to which bring down the cache level when eviction is triggered |0.9| |managedLedgerCacheEvictionFrequency| Configure the cache eviction frequency for the managed ledger cache (evictions/sec) | 100.0 | |managedLedgerCacheEvictionTimeThresholdMillis| All entries that have stayed in cache for more than the configured time, will be evicted | 1000 | |managedLedgerCursorBackloggedThreshold| Configure the threshold (in number of entries) from where a cursor should be considered 'backlogged' and thus should be set as inactive. | 1000| |managedLedgerDefaultMarkDeleteRateLimit| Rate limit the amount of writes per second generated by consumer acking the messages |1.0| |managedLedgerMaxEntriesPerLedger| Max number of entries to append to a ledger before triggering a rollover. A ledger rollover is triggered on these conditions:</p>
<ul>
<li>Either the max rollover time has been reached</li>
<li>or max entries have been written to the ledged and at least min-time has passed|50000| |managedLedgerMinLedgerRolloverTimeMinutes| Minimum time between ledger rollover for a topic |10| |managedLedgerMaxLedgerRolloverTimeMinutes| Maximum time before forcing a ledger rollover for a topic |240| |managedLedgerCursorMaxEntriesPerLedger| Max number of entries to append to a cursor ledger |50000| |managedLedgerCursorRolloverTimeInSeconds| Max time before triggering a rollover on a cursor ledger |14400| |managedLedgerMaxUnackedRangesToPersist| Max number of “acknowledgment holes” that are going to be persistently stored. When acknowledging out of order, a consumer will leave holes that are supposed to be quickly filled by acking all the messages. The information of which messages are acknowledged is persisted by compressing in “ranges” of messages that were acknowledged. After the max number of ranges is reached, the information will only be tracked in memory and messages will be redelivered in case of crashes. |1000| |autoSkipNonRecoverableData| Skip reading non-recoverable/unreadable data-ledger under managed-ledger’s list.It helps when data-ledgers gets corrupted at bookkeeper and managed-cursor is stuck at that ledger. |false| |loadBalancerEnabled| Enable load balancer |true| |loadBalancerPlacementStrategy| Strategy to assign a new bundle weightedRandomSelection || |loadBalancerReportUpdateThresholdPercentage| Percentage of change to trigger load report update |10| |loadBalancerReportUpdateMaxIntervalMinutes| maximum interval to update load report |15| |loadBalancerHostUsageCheckIntervalMinutes| Frequency of report to collect |1| |loadBalancerSheddingIntervalMinutes| Load shedding interval. Broker periodically checks whether some traffic should be offload from some over-loaded broker to other under-loaded brokers |30| |loadBalancerSheddingGracePeriodMinutes| Prevent the same topics to be shed and moved to other broker more that once within this timeframe |30| |loadBalancerBrokerMaxTopics| Usage threshold to allocate max number of topics to broker |50000| |loadBalancerBrokerUnderloadedThresholdPercentage| Usage threshold to determine a broker as under-loaded |1| |loadBalancerBrokerOverloadedThresholdPercentage| Usage threshold to determine a broker as over-loaded |85| |loadBalancerResourceQuotaUpdateIntervalMinutes| Interval to update namespace bundle resource quotat |15| |loadBalancerBrokerComfortLoadLevelPercentage| Usage threshold to determine a broker is having just right level of load |65| |loadBalancerAutoBundleSplitEnabled| enable/disable namespace bundle auto split |false| |loadBalancerNamespaceBundleMaxTopics| maximum topics in a bundle, otherwise bundle split will be triggered |1000| |loadBalancerNamespaceBundleMaxSessions| maximum sessions (producers + consumers) in a bundle, otherwise bundle split will be triggered |1000| |loadBalancerNamespaceBundleMaxMsgRate| maximum msgRate (in + out) in a bundle, otherwise bundle split will be triggered |1000| |loadBalancerNamespaceBundleMaxBandwidthMbytes| maximum bandwidth (in + out) in a bundle, otherwise bundle split will be triggered |100| |loadBalancerNamespaceMaximumBundles| maximum number of bundles in a namespace |128| |replicationMetricsEnabled| Enable replication metrics |true| |replicationConnectionsPerBroker| Max number of connections to open for each broker in a remote cluster More connections host-to-host lead to better throughput over high-latency links. |16| |replicationProducerQueueSize| Replicator producer queue size |1000| |replicatorPrefix| Replicator prefix used for replicator producer name and cursor name pulsar.repl|| |replicationTlsEnabled| Enable TLS when talking with other clusters to replicate messages |false| |brokerServicePurgeInactiveFrequencyInSeconds|Deprecated. 使用方式
<code>brokerDeleteInactiveTopicsFrequencySeconds</code>.|60| |transactionCoordinatorEnabled|Whether to enable transaction coordinator in broker.|true| |transactionMetadataStoreProviderClassName| |org.apache.pulsar.transaction.coordinator.impl.InMemTransactionMetadataStoreProvider| |defaultRetentionTimeInMinutes| Default message retention time || |defaultRetentionSizeInMB| Default retention size |0| |keepAliveIntervalSeconds| How often to check whether the connections are still alive |30| |bootstrapNamespaces| The bootstrap name. | N/A | |loadManagerClassName| Name of load manager to use |org.apache.pulsar.broker.loadbalance.impl.SimpleLoadManagerImpl| |supportedNamespaceBundleSplitAlgorithms| Supported algorithms name for namespace bundle split |[range_equally_divide,topic_count_equally_divide]| |defaultNamespaceBundleSplitAlgorithm| Default algorithm name for namespace bundle split |range_equally_divide| |managedLedgerOffloadDriver| The directory for all the offloader implementations <code>offloadersDirectory=./offloaders</code>. Driver to use to offload old data to long term storage (Possible values: S3, aws-s3, google-cloud-storage). When using google-cloud-storage, Make sure both Google Cloud Storage and Google Cloud Storage JSON API are enabled for the project (check from Developers Console -&gt; Api&amp;auth -&gt; APIs). || |managedLedgerOffloadMaxThreads| Maximum number of thread pool threads for ledger offloading |2| |managedLedgerOffloadPrefetchRounds|The maximum prefetch rounds for ledger reading for offloading.|1| |managedLedgerUnackedRangesOpenCacheSetEnabled| Use Open Range-Set to cache unacknowledged messages |true| |managedLedgerOffloadDeletionLagMs|Delay between a ledger being successfully offloaded to long term storage and the ledger being deleted from bookkeeper | 14400000| |managedLedgerOffloadAutoTriggerSizeThresholdBytes|The number of bytes before triggering automatic offload to long term storage |-1 (disabled)| |s3ManagedLedgerOffloadRegion| For Amazon S3 ledger offload, AWS region || |s3ManagedLedgerOffloadBucket| For Amazon S3 ledger offload, Bucket to place offloaded ledger into || |s3ManagedLedgerOffloadServiceEndpoint| For Amazon S3 ledger offload, Alternative endpoint to connect to (useful for testing) || |s3ManagedLedgerOffloadMaxBlockSizeInBytes| For Amazon S3 ledger offload, Max block size in bytes. (64MB by default, 5MB minimum) |67108864| |s3ManagedLedgerOffloadReadBufferSizeInBytes| For Amazon S3 ledger offload, Read buffer size in bytes (1MB by default) |1048576| |gcsManagedLedgerOffloadRegion|For Google Cloud Storage ledger offload, region where offload bucket is located. Go to this page for more details: <a href="https://cloud.google.com/storage/docs/bucket-locations">https://cloud.google.com/storage/docs/bucket-locations</a> .|N/A| |gcsManagedLedgerOffloadBucket|For Google Cloud Storage ledger offload, Bucket to place offloaded ledger into.|N/A| |gcsManagedLedgerOffloadMaxBlockSizeInBytes|For Google Cloud Storage ledger offload, the maximum block size in bytes. (64MB by default, 5MB minimum)|67108864| |gcsManagedLedgerOffloadReadBufferSizeInBytes|For Google Cloud Storage ledger offload, Read buffer size in bytes. (1MB by default)|1048576| |gcsManagedLedgerOffloadServiceAccountKeyFile|For Google Cloud Storage, path to json file containing service account credentials. For more details, see the &quot;Service Accounts&quot; section of <a href="https://support.google.com/googleapi/answer/6158849">https://support.google.com/googleapi/answer/6158849</a> .|N/A| |fileSystemProfilePath|For File System Storage, file system profile path.|../conf/filesystem_offload_core_site.xml| |fileSystemURI|For File System Storage, file system uri.|N/A| |s3ManagedLedgerOffloadRole| For Amazon S3 ledger offload, provide a role to assume before writing to s3 || |s3ManagedLedgerOffloadRoleSessionName| For Amazon S3 ledger offload, provide a role session name when using a role |pulsar-s3-offload| | acknowledgmentAtBatchIndexLevelEnabled | Enable or disable the batch index acknowledgement. | false | |enableReplicatedSubscriptions|Whether to enable tracking of replicated subscriptions state across clusters.|true| |replicatedSubscriptionsSnapshotFrequencyMillis|The frequency of snapshots for replicated subscriptions tracking.|1000| |replicatedSubscriptionsSnapshotTimeoutSeconds|The timeout for building a consistent snapshot for tracking replicated subscriptions state.|30| |replicatedSubscriptionsSnapshotMaxCachedPerSubscription|The maximum number of snapshot to be cached per subscription.|10| |maxMessagePublishBufferSizeInMB|The maximum memory size for broker handling messages sent from producers. If the processing message size exceeds this value, broker stops reading data from the connection. The processing messages means messages are sent to broker but broker have not sent response to the client. Usually the message are waiting to be written to bookies. It's shared across all the topics running in the same broker. The value <code>-1</code> disables the memory limitation. By default, it is 50% of direct memory.|N/A| |messagePublishBufferCheckIntervalInMillis|Interval between checks to see if message publish buffer size exceeds the maximum. 使用方式 <code>0</code> or negative number to disable the max publish buffer limiting.|100| |retentionCheckIntervalInSeconds|Check between intervals to see if consumed ledgers need to be trimmed. Use 0 or negative number to disable the check.|120| | maxMessageSize | Set the maximum size of a message. | 5242880 | | preciseTopicPublishRateLimiterEnable | Enable precise topic publish rate limiting. | false |</p></li>
</ul>
<h2><a class="anchor" aria-hidden="true" id="client"></a><a href="#client" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Client</h2>
<p>The <a href="/docs/zh-TW/next/reference-cli-tools#pulsar-client"><code>pulsar-client</code></a> CLI tool can be used to publish messages to Pulsar and consume messages from Pulsar topics. This tool can be used in lieu of a client library.</p>
<p>TLS TrustStore type configuration.</p>
<ul>
<li>JKS
<ul>
<li><p>PKCS12</td>
</tr>
</tbody> </table></p>
<h2><a class="anchor" aria-hidden="true" id="service-discovery"></a><a href="#service-discovery" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Service discovery</h2>
<table>
<thead>
<tr><th>Name</th><th>Description</th><th>Default</th></tr>
</thead>
<tbody>
<tr><td>zookeeperServers</td><td>Zookeeper quorum connection string (comma-separated)</td><td></td></tr>
<tr><td>zooKeeperCacheExpirySeconds</td><td>ZooKeeper cache expiry time in seconds</td><td>300</td></tr>
<tr><td>configurationStoreServers</td><td>Configuration store connection string (as a comma-separated list)</td><td></td></tr>
<tr><td>zookeeperSessionTimeoutMs</td><td>ZooKeeper session timeout</td><td>30000</td></tr>
<tr><td>servicePort</td><td>Port to use to server binary-proto request</td><td>6650</td></tr>
<tr><td>servicePortTls</td><td>Port to use to server binary-proto-tls request</td><td>6651</td></tr>
<tr><td>webServicePort</td><td>Port that discovery service listen on</td><td>8080</td></tr>
<tr><td>webServicePortTls</td><td>Port to use to server HTTPS request</td><td>8443</td></tr>
<tr><td>bindOnLocalhost</td><td>Control whether to bind directly on localhost rather than on normal hostname</td><td>false</td></tr>
<tr><td>authenticationEnabled</td><td>Enable authentication</td><td>false</td></tr>
<tr><td>authenticationProviders</td><td>Authentication provider name list, which is comma separated list of class names (comma-separated)</td><td></td></tr>
<tr><td>authorizationEnabled</td><td>Enforce authorization</td><td>false</td></tr>
<tr><td>superUserRoles</td><td>Role names that are treated as “super-user”, meaning they will be able to do all admin operations and publish/consume from all topics (comma-separated)</td><td></td></tr>
<tr><td>tlsEnabled</td><td>Enable TLS</td><td>false</td></tr>
<tr><td>tlsCertificateFilePath</td><td>Path for the TLS certificate file</td><td></td></tr>
<tr><td>tlsKeyFilePath</td><td>Path for the TLS private key file</td><td></td></tr>
</tbody>
</table>
<h2><a class="anchor" aria-hidden="true" id="log4j"></a><a href="#log4j" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Log4j</h2>
<table>
<thead>
<tr><th>Name</th><th>Default</th></tr>
</thead>
<tbody>
<tr><td>pulsar.root.logger</td><td>WARN,CONSOLE</td></tr>
<tr><td>pulsar.log.dir</td><td>logs</td></tr>
<tr><td>pulsar.log.file</td><td>pulsar.log</td></tr>
<tr><td>log4j.rootLogger</td><td>${pulsar.root.logger}</td></tr>
<tr><td>log4j.appender.CONSOLE</td><td>org.apache.log4j.ConsoleAppender</td></tr>
<tr><td>log4j.appender.CONSOLE.Threshold</td><td>DEBUG</td></tr>
<tr><td>log4j.appender.CONSOLE.layout</td><td>org.apache.log4j.PatternLayout</td></tr>
<tr><td>log4j.appender.CONSOLE.layout.ConversionPattern</td><td>%d{ISO8601} - %-5p - [%t:%C{1}@%L] - %m%n</td></tr>
<tr><td>log4j.appender.ROLLINGFILE</td><td>org.apache.log4j.DailyRollingFileAppender</td></tr>
<tr><td>log4j.appender.ROLLINGFILE.Threshold</td><td>DEBUG</td></tr>
<tr><td>log4j.appender.ROLLINGFILE.File</td><td>${pulsar.log.dir}/${pulsar.log.file}</td></tr>
<tr><td>log4j.appender.ROLLINGFILE.layout</td><td>org.apache.log4j.PatternLayout</td></tr>
<tr><td>log4j.appender.ROLLINGFILE.layout.ConversionPattern</td><td>%d{ISO8601} - %-5p [%t:%C{1}@%L] - %m%n</td></tr>
<tr><td>log4j.appender.TRACEFILE</td><td>org.apache.log4j.FileAppender</td></tr>
<tr><td>log4j.appender.TRACEFILE.Threshold</td><td>TRACE</td></tr>
<tr><td>log4j.appender.TRACEFILE.File</td><td>pulsar-trace.log</td></tr>
<tr><td>log4j.appender.TRACEFILE.layout</td><td>org.apache.log4j.PatternLayout</td></tr>
<tr><td>log4j.appender.TRACEFILE.layout.ConversionPattern</td><td>%d{ISO8601} - %-5p [%t:%C{1}@%L][%x] - %m%n</td></tr>
</tbody>
</table>
<blockquote>
<p>Note: 'topic' in log4j2.appender is configurable. - If you want to append all logs to a single topic, set the same topic name. - If you want to append logs to different topics, you can set different topic names.</p>
</blockquote>
<h2><a class="anchor" aria-hidden="true" id="log4j-shell"></a><a href="#log4j-shell" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Log4j shell</h2>
<table>
<thead>
<tr><th>Name</th><th>Default</th></tr>
</thead>
<tbody>
<tr><td>bookkeeper.root.logger</td><td>ERROR,CONSOLE</td></tr>
<tr><td>log4j.rootLogger</td><td>${bookkeeper.root.logger}</td></tr>
<tr><td>log4j.appender.CONSOLE</td><td>org.apache.log4j.ConsoleAppender</td></tr>
<tr><td>log4j.appender.CONSOLE.Threshold</td><td>DEBUG</td></tr>
<tr><td>log4j.appender.CONSOLE.layout</td><td>org.apache.log4j.PatternLayout</td></tr>
<tr><td>log4j.appender.CONSOLE.layout.ConversionPattern</td><td>%d{ABSOLUTE} %-5p %m%n</td></tr>
<tr><td>log4j.logger.org.apache.zookeeper</td><td>ERROR</td></tr>
<tr><td>log4j.logger.org.apache.bookkeeper</td><td>ERROR</td></tr>
<tr><td>log4j.logger.org.apache.bookkeeper.bookie.BookieShell</td><td>INFO</td></tr>
</tbody>
</table>
<h2><a class="anchor" aria-hidden="true" id="standalone"></a><a href="#standalone" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Standalone</h2>
<p>|Name|Description|Default| |---|---|---| |authenticateOriginalAuthData| If this flag is set to <code>true</code>, the broker authenticates the original Auth data; else it just accepts the originalPrincipal and authorizes it (if required). |false| |zookeeperServers| The quorum connection string for local ZooKeeper || |zooKeeperCacheExpirySeconds|ZooKeeper cache expiry time in seconds|300 |configurationStoreServers| Configuration store connection string (as a comma-separated list) || |brokerServicePort| The port on which the standalone broker listens for connections |6650| |webServicePort| THe port used by the standalone broker for HTTP requests |8080| |bindAddress| The hostname or IP address on which the standalone service binds |0.0.0.0| |advertisedAddress| The hostname or IP address that the standalone service advertises to the outside world. If not set, the value of <code>InetAddress.getLocalHost().getHostName()</code> is used. || | numIOThreads | Number of threads to use for Netty IO | 2 * Runtime.getRuntime().availableProcessors() | | numHttpServerThreads | Number of threads to use for HTTP requests processing | 2 * Runtime.getRuntime().availableProcessors()| |isRunningStandalone|This flag controls features that are meant to be used when running in standalone mode.|N/A| |clusterName| The name of the cluster that this broker belongs to. |standalone| | failureDomainsEnabled | Enable cluster's failure-domain which can distribute brokers into logical region. | false | |zooKeeperSessionTimeoutMillis| The ZooKeeper session timeout, in milliseconds. |30000| |zooKeeperOperationTimeoutSeconds|ZooKeeper operation timeout in seconds.|30| |brokerShutdownTimeoutMs| The time to wait for graceful broker shutdown. After this time elapses, the process will be killed. |60000| |skipBrokerShutdownOnOOM| Flag to skip broker shutdown when broker handles Out of memory error. |false| |backlogQuotaCheckEnabled| Enable the backlog quota check, which enforces a specified action when the quota is reached. |true| |backlogQuotaCheckIntervalInSeconds| How often to check for topics that have reached the backlog quota. |60| |backlogQuotaDefaultLimitGB| The default per-topic backlog quota limit. Being less than 0 means no limitation. By default, it is -1. |-1| |ttlDurationDefaultInSeconds| The default ttl for namespaces if ttl is not configured at namespace policies. |0| |brokerDeleteInactiveTopicsEnabled| Enable the deletion of inactive topics. |true| |brokerDeleteInactiveTopicsFrequencySeconds| How often to check for inactive topics, in seconds. |60| | maxPendingPublishdRequestsPerConnection | Maximum pending publish requests per connection to avoid keeping large number of pending requests in memory | 1000| |messageExpiryCheckIntervalInMinutes| How often to proactively check and purged expired messages. |5| |activeConsumerFailoverDelayTimeMillis| How long to delay rewinding cursor and dispatching messages when active consumer is changed. |1000| | subscriptionExpirationTimeMinutes | How long to delete inactive subscriptions from last consumption. When it is set to 0, inactive subscriptions are not deleted automatically | 0 | | subscriptionRedeliveryTrackerEnabled | Enable subscription message redelivery tracker to send redelivery count to consumer. | true | |subscriptionKeySharedEnable|Whether to enable the Key_Shared subscription.|true| | subscriptionKeySharedUseConsistentHashing | In the Key_Shared subscription mode, with default AUTO_SPLIT mode, use splitting ranges or consistent hashing to reassign keys to new consumers. | false | | subscriptionKeySharedConsistentHashingReplicaPoints | In the Key_Shared subscription mode, the number of points in the consistent-hashing ring. The greater the number, the more equal the assignment of keys to consumers. | 100 | | subscriptionExpiryCheckIntervalInMinutes | How frequently to proactively check and purge expired subscription |5 | | brokerDeduplicationEnabled | Set the default behavior for message deduplication in the broker. This can be overridden per-namespace. If it is enabled, the broker rejects messages that are already stored in the topic. | false | | brokerDeduplicationMaxNumberOfProducers | Maximum number of producer information that it's going to be persisted for deduplication purposes | 10000 | | brokerDeduplicationEntriesInterval | Number of entries after which a deduplication information snapshot is taken. A greater interval leads to less snapshots being taken though it would increase the topic recovery time, when the entries published after the snapshot need to be replayed. | 1000 | | brokerDeduplicationProducerInactivityTimeoutMinutes | The time of inactivity (in minutes) after which the broker discards deduplication information related to a disconnected producer. | 360 | | defaultNumberOfNamespaceBundles | When a namespace is created without specifying the number of bundles, this value is used as the default setting.| 4 | |clientLibraryVersionCheckEnabled| Enable checks for minimum allowed client library version. |false| |clientLibraryVersionCheckAllowUnversioned| Allow client libraries with no version information |true| |statusFilePath| The path for the file used to determine the rotation status for the broker when responding to service discovery health checks |/usr/local/apache/htdocs| |maxUnackedMessagesPerConsumer| The maximum number of unacknowledged messages allowed to be received by consumers on a shared subscription. The broker will stop sending messages to a consumer once this limit is reached or until the consumer begins acknowledging messages. A value of 0 disables the unacked message limit check and thus allows consumers to receive messages without any restrictions. |50000| |maxUnackedMessagesPerSubscription| The same as above, except per subscription rather than per consumer. |200000| | maxUnackedMessagesPerBroker | Maximum number of unacknowledged messages allowed per broker. Once this limit reaches, the broker stops dispatching messages to all shared subscriptions which has a higher number of unacknowledged messages until subscriptions start acknowledging messages back and unacknowledged messages count reaches to limit/2. When the value is set to 0, unacknowledged message limit check is disabled and broker does not block dispatchers. | 0 | | maxUnackedMessagesPerSubscriptionOnBrokerBlocked | Once the broker reaches maxUnackedMessagesPerBroker limit, it blocks subscriptions which have higher unacknowledged messages than this percentage limit and subscription does not receive any new messages until that subscription acknowledges messages back. | 0.16 | |maxNumPartitionsPerPartitionedTopic|Max number of partitions per partitioned topic. Use 0 or negative number to disable the check|0| |zookeeperSessionExpiredPolicy|There are two policies when ZooKeeper session expired happens, &quot;shutdown&quot; and &quot;reconnect&quot;. If it is set to &quot;shutdown&quot; policy, when ZooKeeper session expired happens, the broker is shutdown. If it is set to &quot;reconnect&quot; policy, the broker tries to reconnect to ZooKeeper server and re-register metadata to ZooKeeper. Note: the &quot;reconnect&quot; policy is an experiment feature.|shutdown| | topicPublisherThrottlingTickTimeMillis | Tick time to schedule task that checks topic publish rate limiting across all topics. A lower value can improve accuracy while throttling publish but it uses more CPU to perform frequent check. (Disable publish throttling with value 0) | 10| | brokerPublisherThrottlingTickTimeMillis | Tick time to schedule task that checks broker publish rate limiting across all topics. A lower value can improve accuracy while throttling publish but it uses more CPU to perform frequent check. When the value is set to 0, publish throttling is disabled. |50 | | brokerPublisherThrottlingMaxMessageRate | Maximum rate (in 1 second) of messages allowed to publish for a broker if the message rate limiting is enabled. When the value is set to 0, message rate limiting is disabled. | 0| | brokerPublisherThrottlingMaxByteRate | Maximum rate (in 1 second) of bytes allowed to publish for a broker if the byte rate limiting is enabled. When the value is set to 0, the byte rate limiting is disabled. | 0 | |subscribeThrottlingRatePerConsumer|Too many subscribe requests from a consumer can cause broker rewinding consumer cursors and loading data from bookies, hence causing high network bandwidth usage. When the positive value is set, broker will throttle the subscribe requests for one consumer. Otherwise, the throttling will be disabled. By default, throttling is disabled.|0| |subscribeRatePeriodPerConsumerInSecond|Rate period for {subscribeThrottlingRatePerConsumer}. By default, it is 30s.|30| | dispatchThrottlingRatePerTopicInMsg | Default messages (per second) dispatch throttling-limit for every topic. When the value is set to 0, default message dispatch throttling-limit is disabled. |0 | | dispatchThrottlingRatePerTopicInByte | Default byte (per second) dispatch throttling-limit for every topic. When the value is set to 0, default byte dispatch throttling-limit is disabled. | 0| | dispatchThrottlingRateRelativeToPublishRate | Enable dispatch rate-limiting relative to publish rate. | false | |dispatchThrottlingRatePerSubscriptionInMsg|The defaulted number of message dispatching throttling-limit for a subscription. The value of 0 disables message dispatch-throttling.|0| |dispatchThrottlingRatePerSubscriptionInByte|The default number of message-bytes dispatching throttling-limit for a subscription. The value of 0 disables message-byte dispatch-throttling.|0| | dispatchThrottlingOnNonBacklogConsumerEnabled | Enable dispatch-throttling for both caught up consumers as well as consumers who have backlogs. | true | |dispatcherMaxReadBatchSize|The maximum number of entries to read from BookKeeper. By default, it is 100 entries.|100| |dispatcherMaxReadSizeBytes|The maximum size in bytes of entries to read from BookKeeper. By default, it is 5MB.|5242880| |dispatcherMinReadBatchSize|The minimum number of entries to read from BookKeeper. By default, it is 1 entry. When there is an error occurred on reading entries from bookkeeper, the broker will backoff the batch size to this minimum number.|1| |dispatcherMaxRoundRobinBatchSize|The maximum number of entries to dispatch for a shared subscription. By default, it is 20 entries.|20| | preciseDispatcherFlowControl | Precise dispathcer flow control according to history message number of each entry. | false | | maxConcurrentLookupRequest | Maximum number of concurrent lookup request that the broker allows to throttle heavy incoming lookup traffic. | 50000 | | maxConcurrentTopicLoadRequest | Maximum number of concurrent topic loading request that the broker allows to control the number of zk-operations. | 5000 | | maxConcurrentNonPersistentMessagePerConnection | Maximum number of concurrent non-persistent message that can be processed per connection. | 1000 | | numWorkerThreadsForNonPersistentTopic | Number of worker threads to serve non-persistent topic. | 8 | | enablePersistentTopics | Enable broker to load persistent topics. | true | | enableNonPersistentTopics | Enable broker to load non-persistent topics. | true | | maxProducersPerTopic | Maximum number of producers allowed to connect to topic. Once this limit reaches, the broker rejects new producers until the number of connected producers decreases. When the value is set to 0, maxProducersPerTopic-limit check is disabled. | 0 | | maxConsumersPerTopic | Maximum number of consumers allowed to connect to topic. Once this limit reaches, the broker rejects new consumers until the number of connected consumers decreases. When the value is set to 0, maxConsumersPerTopic-limit check is disabled. | 0 | | maxConsumersPerSubscription | Maximum number of consumers allowed to connect to subscription. Once this limit reaches, the broker rejects new consumers until the number of connected consumers decreases. When the value is set to 0, maxConsumersPerSubscription-limit check is disabled. | 0 | | maxNumPartitionsPerPartitionedTopic | Maximum number of partitions per partitioned topic. When the value is set to a negative number or is set to 0, the check is disabled. | 0 | | tlsCertRefreshCheckDurationSec | TLS certificate refresh duration in seconds. When the value is set to 0, check the TLS certificate on every new connection. | 300 | | tlsCertificateFilePath | Path for the TLS certificate file. | | | tlsKeyFilePath | Path for the TLS private key file. | | | tlsTrustCertsFilePath | Path for the trusted TLS certificate file.| | | tlsAllowInsecureConnection | Accept untrusted TLS certificate from the client. If it is set to true, a client with a certificate which cannot be verified with the 'tlsTrustCertsFilePath' certificate is allowed to connect to the server, though the certificate is not be used for client authentication. | false | | tlsProtocols | Specify the TLS protocols the broker uses to negotiate during TLS handshake. | | | tlsCiphers | Specify the TLS cipher the broker uses to negotiate during TLS Handshake. | | | tlsRequireTrustedClientCertOnConnect | Trusted client certificates are required for to connect TLS. Reject the Connection if the client certificate is not trusted. In effect, this requires that all connecting clients perform TLS client authentication. | false | | tlsEnabledWithKeyStore | Enable TLS with KeyStore type configuration in broker. | false | | tlsProvider | TLS Provider for KeyStore type. | | | tlsKeyStoreType | TLS KeyStore type configuration in the broker.</p>
<ul>
<li>JKS
<ul>
<li>PKCS12 |JKS| | tlsKeyStore | TLS KeyStore path in the broker. | | | tlsKeyStorePassword | TLS KeyStore password for the broker. | | | tlsTrustStoreType | TLS TrustStore type configuration in the broker
<ul>
<li>JKS
<ul>
<li>PKCS12 |JKS| | tlsTrustStore | TLS TrustStore path in the broker. | | | tlsTrustStorePassword | TLS TrustStore password for the broker. | | | brokerClientTlsEnabledWithKeyStore | Configure whether the internal client uses the KeyStore type to authenticate with Pulsar brokers. | false | | brokerClientSslProvider | The TLS Provider used by the internal client to authenticate with other Pulsar brokers. | | | brokerClientTlsTrustStoreType | TLS TrustStore type configuration for the internal client to authenticate with Pulsar brokers.
<ul>
<li>JKS
<ul>
<li><p>PKCS12 | JKS | | brokerClientTlsTrustStore | TLS TrustStore path for the internal client to authenticate with Pulsar brokers. | | | brokerClientTlsTrustStorePassword | TLS TrustStore password for the internal client to authenticate with Pulsar brokers. | | | brokerClientTlsCiphers | Specify the TLS cipher that the internal client uses to negotiate during TLS Handshake. | | | brokerClientTlsProtocols | Specify the TLS protocols that the broker uses to negotiate during TLS handshake. | | systemTopicEnabled | Enable/Disable system topics. | false | | topicLevelPoliciesEnabled | Enable or disable topic level policies. Topic level policies depends on the system topic. Please enable the system topic first. | false | | proxyRoles | Role names that are treated as &quot;proxy roles&quot;. If the broker sees a request with role as proxyRoles, it demands to see a valid original principal. | | | authenticateOriginalAuthData | If this flag is set, the broker authenticates the original Auth data. Otherwise, it just accepts the originalPrincipal and authorizes it (if required). | false | |authenticationEnabled| Enable authentication for the broker. |false| |authenticationProviders| A comma-separated list of class names for authentication providers. |false| |authorizationEnabled| Enforce authorization in brokers. |false| | authorizationProvider | Authorization provider fully qualified class-name. | org.apache.pulsar.broker.authorization.PulsarAuthorizationProvider | | authorizationAllowWildcardsMatching | Allow wildcard matching in authorization. Wildcard matching is applicable only when the wildcard-character (<em>) presents at the <strong>first</strong> or <strong>last</strong> position. | false | |superUserRoles| Role names that are treated as “superusers.” Superusers are authorized to perform all admin tasks. | | |brokerClientAuthenticationPlugin| The authentication settings of the broker itself. Used when the broker connects to other brokers either in the same cluster or from other clusters. | | |brokerClientAuthenticationParameters| The parameters that go along with the plugin specified using brokerClientAuthenticationPlugin. | | |athenzDomainNames| Supported Athenz authentication provider domain names as a comma-separated list. | | | anonymousUserRole | When this parameter is not empty, unauthenticated users perform as anonymousUserRole. | | |tokenAuthClaim| Specify the token claim that will be used as the authentication &quot;principal&quot; or &quot;role&quot;. The &quot;subject&quot; field will be used if this is left blank || |tokenAudienceClaim| The token audience &quot;claim&quot; name, e.g. &quot;aud&quot;. It is used to get the audience from token. If it is not set, the audience is not verified. || | tokenAudience | The token audience stands for this broker. The field <code>tokenAudienceClaim</code> of a valid token need contains this parameter.| | |saslJaasClientAllowedIds|This is a regexp, which limits the range of possible ids which can connect to the Broker using SASL. By default, it is set to <code>SaslConstants.JAAS_CLIENT_ALLOWED_IDS_DEFAULT</code>, which is &quot;.</em>pulsar.*&quot;, so only clients whose id contains 'pulsar' are allowed to connect.|N/A| |saslJaasBrokerSectionName|Service Principal, for login context name. By default, it is set to <code>SaslConstants.JAAS_DEFAULT_BROKER_SECTION_NAME</code>, which is &quot;Broker&quot;.|N/A| |httpMaxRequestSize|If the value is larger than 0, it rejects all HTTP requests with bodies larged than the configured limit.|-1| |exposePreciseBacklogInPrometheus| Enable expose the precise backlog stats, set false to use published counter and consumed counter to calculate, this would be more efficient but may be inaccurate. |false| |bookkeeperMetadataServiceUri|Metadata service uri is what BookKeeper used for loading corresponding metadata driver and resolving its metadata service location. This value can be fetched using <code>bookkeeper shell whatisinstanceid</code> command in BookKeeper cluster. For example: <code>zk+hierarchical://localhost:2181/ledgers</code>. The metadata service uri list can also be semicolon separated values like: <code>zk+hierarchical://zk1:2181;zk2:2181;zk3:2181/ledgers</code>.|N/A| |bookkeeperClientAuthenticationPlugin| Authentication plugin to be used when connecting to bookies (BookKeeper servers). || |bookkeeperClientAuthenticationParametersName| BookKeeper authentication plugin implementation parameters and values. || |bookkeeperClientAuthenticationParameters| Parameters associated with the bookkeeperClientAuthenticationParametersName || |bookkeeperClientTimeoutInSeconds| Timeout for BookKeeper add and read operations. |30| |bookkeeperClientSpeculativeReadTimeoutInMillis| Speculative reads are initiated if a read request doesn’t complete within a certain time. A value of 0 disables speculative reads. |0| |bookkeeperUseV2WireProtocol|Use older Bookkeeper wire protocol with bookie.|true| |bookkeeperClientHealthCheckEnabled| Enable bookie health checks. |true| |bookkeeperClientHealthCheckIntervalSeconds| The time interval, in seconds, at which health checks are performed. New ledgers are not created during health checks. |60| |bookkeeperClientHealthCheckErrorThresholdPerInterval| Error threshold for health checks. |5| |bookkeeperClientHealthCheckQuarantineTimeInSeconds| If bookies have more than the allowed number of failures within the time interval specified by bookkeeperClientHealthCheckIntervalSeconds |1800| |bookkeeperGetBookieInfoIntervalSeconds|Specify options for the GetBookieInfo check. This setting helps ensure the list of bookies that are up to date on the brokers.|86400| |bookkeeperGetBookieInfoRetryIntervalSeconds|Specify options for the GetBookieInfo check. This setting helps ensure the list of bookies that are up to date on the brokers.|60| |bookkeeperClientRackawarePolicyEnabled| |true| |bookkeeperClientRegionawarePolicyEnabled| |false| |bookkeeperClientMinNumRacksPerWriteQuorum| |2| |bookkeeperClientMinNumRacksPerWriteQuorum| |false| |bookkeeperClientReorderReadSequenceEnabled| |false| |bookkeeperClientIsolationGroups||| |bookkeeperClientSecondaryIsolationGroups| Enable bookie secondary-isolation group if bookkeeperClientIsolationGroups doesn't have enough bookie available. || |bookkeeperClientMinAvailableBookiesInIsolationGroups| Minimum bookies that should be available as part of bookkeeperClientIsolationGroups else broker will include bookkeeperClientSecondaryIsolationGroups bookies in isolated list. || | bookkeeperTLSProviderFactoryClass | Set the client security provider factory class name. | org.apache.bookkeeper.tls.TLSContextFactory | | bookkeeperTLSClientAuthentication | Enable TLS authentication with bookie. | false | | bookkeeperTLSKeyFileType | Supported type: PEM, JKS, PKCS12. | PEM | | bookkeeperTLSTrustCertTypes | Supported type: PEM, JKS, PKCS12. | PEM | | bookkeeperTLSKeyStorePasswordPath | Path to file containing keystore password, if the client keystore is password protected. | | bookkeeperTLSTrustStorePasswordPath | Path to file containing truststore password, if the client truststore is password protected. | | | bookkeeperTLSKeyFilePath | Path for the TLS private key file. | | | bookkeeperTLSCertificateFilePath | Path for the TLS certificate file. | | | bookkeeperTLSTrustCertsFilePath | Path for the trusted TLS certificate file. | | | bookkeeperDiskWeightBasedPlacementEnabled | Enable/Disable disk weight based placement. | false | | bookkeeperExplicitLacIntervalInMills | Set the interval to check the need for sending an explicit LAC. When the value is set to 0, no explicit LAC is sent. | 0 | | bookkeeperClientExposeStatsToPrometheus | Expose BookKeeper client managed ledger stats to Prometheus. | false | |managedLedgerDefaultEnsembleSize| |1| |managedLedgerDefaultWriteQuorum| |1| |managedLedgerDefaultAckQuorum| |1| | managedLedgerDigestType | Default type of checksum to use when writing to BookKeeper. | CRC32C | | managedLedgerNumWorkerThreads | Number of threads to be used for managed ledger tasks dispatching. | 8 | | managedLedgerNumSchedulerThreads | Number of threads to be used for managed ledger scheduled tasks. | 8 | |managedLedgerCacheSizeMB| |N/A| |managedLedgerCacheCopyEntries| Whether to copy the entry payloads when inserting in cache.| false| |managedLedgerCacheEvictionWatermark| |0.9| |managedLedgerCacheEvictionFrequency| Configure the cache eviction frequency for the managed ledger cache (evictions/sec) | 100.0 | |managedLedgerCacheEvictionTimeThresholdMillis| All entries that have stayed in cache for more than the configured time, will be evicted | 1000 | |managedLedgerCursorBackloggedThreshold| Configure the threshold (in number of entries) from where a cursor should be considered 'backlogged' and thus should be set as inactive. | 1000| |managedLedgerUnackedRangesOpenCacheSetEnabled| Use Open Range-Set to cache unacknowledged messages |true| |managedLedgerDefaultMarkDeleteRateLimit| |0.1| |managedLedgerMaxEntriesPerLedger| |50000| |managedLedgerMinLedgerRolloverTimeMinutes| |10| |managedLedgerMaxLedgerRolloverTimeMinutes| |240| |managedLedgerCursorMaxEntriesPerLedger| |50000| |managedLedgerCursorRolloverTimeInSeconds| |14400| | managedLedgerMaxSizePerLedgerMbytes | Maximum ledger size before triggering a rollover for a topic. | 2048 | | managedLedgerMaxUnackedRangesToPersist | Maximum number of &quot;acknowledgment holes&quot; that are going to be persistently stored. When acknowledging out of order, a consumer leaves holes that are supposed to be quickly filled by acknowledging all the messages. The information of which messages are acknowledged is persisted by compressing in &quot;ranges&quot; of messages that were acknowledged. After the max number of ranges is reached, the information is only tracked in memory and messages are redelivered in case of crashes. | 10000 | | managedLedgerMaxUnackedRangesToPersistInZooKeeper | Maximum number of &quot;acknowledgment holes&quot; that can be stored in Zookeeper. If the number of unacknowledged message range is higher than this limit, the broker persists unacknowledged ranges into bookkeeper to avoid additional data overhead into Zookeeper. | 1000 | |autoSkipNonRecoverableData| |false| | managedLedgerMetadataOperationsTimeoutSeconds | Operation timeout while updating managed-ledger metadata. | 60 | | managedLedgerReadEntryTimeoutSeconds | Read entries timeout when the broker tries to read messages from BookKeeper. | 0 | | managedLedgerAddEntryTimeoutSeconds | Add entry timeout when the broker tries to publish message to BookKeeper. | 0 | | managedLedgerNewEntriesCheckDelayInMillis | New entries check delay for the cursor under the managed ledger. If no new messages in the topic, the cursor tries to check again after the delay time. For consumption latency sensitive scenario, you can set the value to a smaller value or 0. Of course, a smaller value may degrade consumption throughput.|10 ms| | managedLedgerPrometheusStatsLatencyRolloverSeconds | Managed ledger prometheus stats latency rollover seconds. | 60 | | managedLedgerTraceTaskExecution | Whether to trace managed ledger task execution time. | true | |managedLedgerNewEntriesCheckDelayInMillis|New entries check delay for the cursor under the managed ledger. If no new messages in the topic, the cursor will try to check again after the delay time. For consumption latency sensitive scenario, it can be set to a smaller value or 0. A smaller value degrades consumption throughput. By default, it is 10ms.|10| |loadBalancerEnabled| |false| |loadBalancerPlacementStrategy| |weightedRandomSelection| |loadBalancerReportUpdateThresholdPercentage| |10| |loadBalancerReportUpdateMaxIntervalMinutes| |15| |loadBalancerHostUsageCheckIntervalMinutes| |1| |loadBalancerSheddingIntervalMinutes| |30| |loadBalancerSheddingGracePeriodMinutes| |30| |loadBalancerBrokerMaxTopics| |50000| |loadBalancerBrokerUnderloadedThresholdPercentage| |1| |loadBalancerBrokerOverloadedThresholdPercentage| |85| |loadBalancerResourceQuotaUpdateIntervalMinutes| |15| |loadBalancerBrokerComfortLoadLevelPercentage| |65| |loadBalancerAutoBundleSplitEnabled| |false| | loadBalancerAutoUnloadSplitBundlesEnabled | Enable/Disable automatic unloading of split bundles. | true | |loadBalancerNamespaceBundleMaxTopics| |1000| |loadBalancerNamespaceBundleMaxSessions| |1000| |loadBalancerNamespaceBundleMaxMsgRate| |1000| |loadBalancerNamespaceBundleMaxBandwidthMbytes| |100| |loadBalancerNamespaceMaximumBundles| |128| | loadBalancerBrokerThresholdShedderPercentage | The broker resource usage threshold. When the broker resource usage is greater than the pulsar cluster average resource usage, the threshold shedder is triggered to offload bundles from the broker. It only takes effect in the ThresholdSheddler strategy. | 10 | | loadBalancerHistoryResourcePercentage | The history usage when calculating new resource usage. It only takes effect in the ThresholdSheddler strategy. | 0.9 | | loadBalancerBandwithInResourceWeight | The BandWithIn usage weight when calculating new resource usage. It only takes effect in the ThresholdSheddler strategy. | 1.0 | | loadBalancerBandwithOutResourceWeight | The BandWithOut usage weight when calculating new resource usage. It only takes effect in the ThresholdSheddler strategy. | 1.0 | | loadBalancerCPUResourceWeight | The CPU usage weight when calculating new resource usage. It only takes effect in the ThresholdSheddler strategy. | 1.0 | | loadBalancerMemoryResourceWeight | The heap memory usage weight when calculating new resource usage. It only takes effect in the ThresholdSheddler strategy. | 1.0 | | loadBalancerDirectMemoryResourceWeight | The direct memory usage weight when calculating new resource usage. It only takes effect in the ThresholdSheddler strategy. | 1.0 | | loadBalancerBundleUnloadMinThroughputThreshold | Bundle unload minimum throughput threshold. Avoid bundle unload frequently. It only takes effect in the ThresholdSheddler strategy. | 10 | |replicationMetricsEnabled| |true| |replicationConnectionsPerBroker| |16| |replicationProducerQueueSize| |1000| | replicationPolicyCheckDurationSeconds | Duration to check replication policy to avoid replicator inconsistency due to missing ZooKeeper watch. When the value is set to 0, disable checking replication policy. | 600 | |defaultRetentionTimeInMinutes| |0| |defaultRetentionSizeInMB| |0| |keepAliveIntervalSeconds| |30|</p></p>
<h2><a class="anchor" aria-hidden="true" id="websocket"></a><a href="#websocket" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>WebSocket</h2>
<table>
<thead>
<tr><th>Name</th><th>Description</th><th>Default</th></tr>
</thead>
<tbody>
<tr><td>configurationStoreServers</td><td></td><td></td></tr>
<tr><td>zooKeeperSessionTimeoutMillis</td><td></td><td>30000</td></tr>
<tr><td>zooKeeperCacheExpirySeconds</td><td>ZooKeeper cache expiry time in seconds</td><td>300</td></tr>
<tr><td>serviceUrl</td><td></td><td></td></tr>
<tr><td>serviceUrlTls</td><td></td><td></td></tr>
<tr><td>brokerServiceUrl</td><td></td><td></td></tr>
<tr><td>brokerServiceUrlTls</td><td></td><td></td></tr>
<tr><td>webServicePort</td><td></td><td>8080</td></tr>
<tr><td>webServicePortTls</td><td></td><td>8443</td></tr>
<tr><td>bindAddress</td><td></td><td>0.0.0.0</td></tr>
<tr><td>clusterName</td><td></td><td></td></tr>
<tr><td>authenticationEnabled</td><td></td><td>false</td></tr>
<tr><td>authenticationProviders</td><td></td><td></td></tr>
<tr><td>authorizationEnabled</td><td></td><td>false</td></tr>
<tr><td>superUserRoles</td><td></td><td></td></tr>
<tr><td>brokerClientAuthenticationPlugin</td><td></td><td></td></tr>
<tr><td>brokerClientAuthenticationParameters</td><td></td><td></td></tr>
<tr><td>tlsEnabled</td><td></td><td>false</td></tr>
<tr><td>tlsAllowInsecureConnection</td><td></td><td>false</td></tr>
<tr><td>tlsCertificateFilePath</td><td></td><td></td></tr>
<tr><td>tlsKeyFilePath</td><td></td><td></td></tr>
<tr><td>tlsTrustCertsFilePath</td><td></td><td></td></tr>
</tbody>
</table>
<h2><a class="anchor" aria-hidden="true" id="pulsar-proxy"></a><a href="#pulsar-proxy" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Pulsar proxy</h2>
<p>The <a href="/docs/zh-TW/next/concepts-architecture-overview#pulsar-proxy">Pulsar proxy</a> can be configured in the <code>conf/proxy.conf</code> file.</p>
<p>Proxy log level</p>
<p>- 0: Do not log any TCP channel information.
- 1: Parse and log any TCP channel information and command information without message body.
- 2: Parse and log channel information, command information and message body.</td>
</tr>
Set the Pulsar Proxy log level.</p>
<pre><code class="hljs">          - If the value is set to 0, no TCP channel information is logged. 
              - If the value is set to 1, only the TCP channel information and command information (without message body) are parsed and logged. 
                  - If the value is set to 2, all TCP channel information, command information, and message body are parsed and logged.&lt;/td&gt; 
                      &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; 
                      ## ZooKeeper
                      
                      ZooKeeper handles a broad range of essential configuration- and coordination-related tasks for Pulsar. The default configuration file for ZooKeeper is in the `conf/zookeeper.conf` file in your Pulsar installation. The following parameters are available:
                      
                      | Name                      | Description                                                                                                                                                                                                                                                                                | Default        |
                      | ------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | -------------- |
                      | tickTime                  | The tick is the basic unit of time in ZooKeeper, measured in milliseconds and used to regulate things like heartbeats and timeouts. tickTime is the length of a single tick.                                                                                                               | 2000           |
                      | initLimit                 | The maximum time, in ticks, that the leader ZooKeeper server allows follower ZooKeeper servers to successfully connect and sync. The tick time is set in milliseconds using the tickTime parameter.                                                                                        | 10             |
                      | syncLimit                 | The maximum time, in ticks, that a follower ZooKeeper server is allowed to sync with other ZooKeeper servers. The tick time is set in milliseconds using the tickTime parameter.                                                                                                           | 5              |
                      | dataDir                   | The location where ZooKeeper will store in-memory database snapshots as well as the transaction log of updates to the database.                                                                                                                                                            | data/zookeeper |
                      | clientPort                | The port on which the ZooKeeper server will listen for connections.                                                                                                                                                                                                                        | 2181           |
                      | admin.enableServer        | The port at which the admin listens.                                                                                                                                                                                                                                                       | true           |
                      | admin.serverPort          | The port at which the admin listens.                                                                                                                                                                                                                                                       | 9990           |
                      | autopurge.snapRetainCount | In ZooKeeper, auto purge determines how many recent snapshots of the database stored in dataDir to retain within the time interval specified by autopurge.purgeInterval (while deleting the rest).                                                                                         | 3              |
                      | autopurge.purgeInterval   | The time interval, in hours, by which the ZooKeeper database purge task is triggered. Setting to a non-zero number will enable auto purge; setting to 0 will disable. Read this guide before enabling auto purge.                                                                          | 1              |
                      | forceSync                 | Requires updates to be synced to media of the transaction log before finishing processing the update. If this option is set to 'no', ZooKeeper will not require updates to be synced to the media. WARNING: it's not recommended to run a production ZK cluster with `forceSync` disabled. | yes            |
                      | maxClientCnxns            | The maximum number of client connections. Increase this if you need to handle more ZooKeeper clients.                                                                                                                                                                                      | 60             |
                      
                      In addition to the parameters in the table above, configuring ZooKeeper for Pulsar involves adding a `server.N` line to the `conf/zookeeper.conf` file for each node in the ZooKeeper cluster, where `N` is the number of the ZooKeeper node. Here's an example for a three-node ZooKeeper cluster:
                      
                      ```properties
                      server.1=zk1.us-west.example.com:2888:3888
                      server.2=zk2.us-west.example.com:2888:3888
                      server.3=zk3.us-west.example.com:2888:3888
                      ```
                      
                      &gt; We strongly recommend consulting the [ZooKeeper Administrator's Guide](https://zookeeper.apache.org/doc/current/zookeeperAdmin.html) for a more thorough and comprehensive introduction to ZooKeeper configuration</code></pre></li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
</ul>
</span></div></article></div><div class="docs-prevnext"></div></div></div><nav class="onPageNav"><ul class="toc-headings"><li><a href="#bookkeeper">BookKeeper</a></li><li><a href="#broker">Broker</a></li><li><a href="#client">Client</a></li><li><a href="#service-discovery">Service discovery</a></li><li><a href="#log4j">Log4j</a></li><li><a href="#log4j-shell">Log4j shell</a></li><li><a href="#standalone">Standalone</a></li><li><a href="#websocket">WebSocket</a></li><li><a href="#pulsar-proxy">Pulsar proxy</a></li></ul></nav></div><footer class="nav-footer" id="footer"><section class="copyright">Copyright © 2020 The Apache Software Foundation. All Rights Reserved. Apache, Apache Pulsar and the Apache feather logo are trademarks of The Apache Software Foundation.</section><span><script>
      const community = document.querySelector("a[href='#community']").parentNode;
      const communityMenu =
        '<li>' +
        '<a id="community-menu" href="#">Community <span style="font-size: 0.75em">&nbsp;▼</span></a>' +
        '<div id="community-dropdown" class="hide">' +
          '<ul id="community-dropdown-items">' +
            '<li><a href="/zh-TW/contact">Contact</a></li>' +
            '<li><a href="/zh-TW/contributing">Contributing</a></li>' +
            '<li><a href="/zh-TW/coding-guide">Coding guide</a></li>' +
            '<li><a href="/zh-TW/events">Events</a></li>' +
            '<li><a href="https://twitter.com/Apache_Pulsar" target="_blank">Twitter &#x2750</a></li>' +
            '<li><a href="https://github.com/apache/pulsar/wiki" target="_blank">Wiki &#x2750</a></li>' +
            '<li><a href="https://github.com/apache/pulsar/issues" target="_blank">Issue tracking &#x2750</a></li>' +
            '<li><a href="https://pulsar-summit.org/" target="_blank">Pulsar Summit &#x2750</a></li>' +
            '<li>&nbsp;</li>' +
            '<li><a href="/zh-TW/resources">Resources</a></li>' +
            '<li><a href="/zh-TW/team">Team</a></li>' +
            '<li><a href="/zh-TW/powered-by">Powered By</a></li>' +
          '</ul>' +
        '</div>' +
        '</li>';

      community.innerHTML = communityMenu;

      const communityMenuItem = document.getElementById("community-menu");
      const communityDropDown = document.getElementById("community-dropdown");
      communityMenuItem.addEventListener("click", function(event) {
        event.preventDefault();

        if (communityDropDown.className == 'hide') {
          communityDropDown.className = 'visible';
        } else {
          communityDropDown.className = 'hide';
        }
      });
    </script></span></footer></div><script type="text/javascript" src="https://cdn.jsdelivr.net/docsearch.js/1/docsearch.min.js"></script><script>window.twttr=(function(d,s, id){var js,fjs=d.getElementsByTagName(s)[0],t=window.twttr||{};if(d.getElementById(id))return t;js=d.createElement(s);js.id=id;js.src='https://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js, fjs);t._e = [];t.ready = function(f) {t._e.push(f);};return t;}(document, 'script', 'twitter-wjs'));</script><script>
                document.addEventListener('keyup', function(e) {
                  if (e.target !== document.body) {
                    return;
                  }
                  // keyCode for '/' (slash)
                  if (e.keyCode === 191) {
                    const search = document.getElementById('search_input_react');
                    search && search.focus();
                  }
                });
              </script><script>
              var search = docsearch({
                
                apiKey: 'd226a455cecdd4bc18a554c1b47e5b52',
                indexName: 'apache_pulsar',
                inputSelector: '#search_input_react',
                algoliaOptions: {"facetFilters":["language:zh-TW","version:next"]}
              });
            </script></body></html>